{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO3glo8fJHrZ",
        "outputId": "d5e8056f-5e01-4f8b-b63c-e78626b72ee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yxh6l9XLDqZ"
      },
      "source": [
        " 1) Training by using CNN-LSTM via images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwYax0h1GSa6",
        "outputId": "34adfd4c-3875-42c0-c38d-2dd415c7a6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.2993 - loss: 1.1359 - val_accuracy: 0.3562 - val_loss: 1.0963\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.3330 - loss: 1.0992 - val_accuracy: 0.3973 - val_loss: 1.0963\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.3696 - loss: 1.0849 - val_accuracy: 0.4452 - val_loss: 1.0472\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.4853 - loss: 1.0444 - val_accuracy: 0.6644 - val_loss: 0.8431\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.6382 - loss: 0.8618 - val_accuracy: 0.7192 - val_loss: 0.6502\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.7554 - loss: 0.6381 - val_accuracy: 0.8082 - val_loss: 0.4955\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8599 - loss: 0.3978 - val_accuracy: 0.8836 - val_loss: 0.3547\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.9394 - loss: 0.2082 - val_accuracy: 0.8836 - val_loss: 0.3592\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.9517 - loss: 0.1773 - val_accuracy: 0.8836 - val_loss: 0.3005\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.9718 - loss: 0.0966 - val_accuracy: 0.9315 - val_loss: 0.1718\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.9715 - loss: 0.1176 - val_accuracy: 0.9726 - val_loss: 0.0900\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.9931 - loss: 0.0559 - val_accuracy: 0.9863 - val_loss: 0.0657\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9807 - loss: 0.0844 - val_accuracy: 0.9658 - val_loss: 0.1392\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.9945 - loss: 0.0328 - val_accuracy: 0.9795 - val_loss: 0.0623\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.9895 - loss: 0.0488 - val_accuracy: 0.9726 - val_loss: 0.0920\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9943 - loss: 0.0385 - val_accuracy: 0.9658 - val_loss: 0.0737\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.9867 - loss: 0.0518 - val_accuracy: 0.9795 - val_loss: 0.0689\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 614ms/step\n",
            "Confusion Matrix:\n",
            "[[49  2  0]\n",
            " [ 0 49  0]\n",
            " [ 0  1 45]]\n",
            "Precision: 0.9808, Recall: 0.9797, Accuracy: 0.9795, F1 Score: 0.9798\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.3647 - loss: 1.1062 - val_accuracy: 0.3493 - val_loss: 1.1348\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.3074 - loss: 1.1245 - val_accuracy: 0.3699 - val_loss: 1.0979\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.3872 - loss: 1.0887 - val_accuracy: 0.4247 - val_loss: 1.1039\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.4453 - loss: 1.0626 - val_accuracy: 0.4589 - val_loss: 1.0399\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.5492 - loss: 0.9610 - val_accuracy: 0.6986 - val_loss: 0.7560\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.7217 - loss: 0.7185 - val_accuracy: 0.7671 - val_loss: 0.5964\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8084 - loss: 0.5303 - val_accuracy: 0.8836 - val_loss: 0.3522\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.8926 - loss: 0.3515 - val_accuracy: 0.8836 - val_loss: 0.3163\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.9236 - loss: 0.2511 - val_accuracy: 0.9452 - val_loss: 0.2400\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9502 - loss: 0.1822 - val_accuracy: 0.9589 - val_loss: 0.2060\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9567 - loss: 0.1917 - val_accuracy: 0.9726 - val_loss: 0.1109\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.9653 - loss: 0.1074 - val_accuracy: 0.9795 - val_loss: 0.0982\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9737 - loss: 0.0919 - val_accuracy: 0.9795 - val_loss: 0.0926\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9764 - loss: 0.0957 - val_accuracy: 0.9658 - val_loss: 0.1311\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9795 - loss: 0.0921 - val_accuracy: 0.9521 - val_loss: 0.1167\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3s/step - accuracy: 0.9844 - loss: 0.0631 - val_accuracy: 0.9795 - val_loss: 0.0647\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9830 - loss: 0.0760 - val_accuracy: 0.9932 - val_loss: 0.0476\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9813 - loss: 0.0663 - val_accuracy: 0.9589 - val_loss: 0.1157\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.9886 - loss: 0.0550 - val_accuracy: 0.9863 - val_loss: 0.0636\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9892 - loss: 0.0538 - val_accuracy: 0.9932 - val_loss: 0.0331\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9978 - loss: 0.0154 - val_accuracy: 0.9932 - val_loss: 0.0283\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9978 - loss: 0.0139 - val_accuracy: 0.9932 - val_loss: 0.0165\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.9978 - loss: 0.0155 - val_accuracy: 0.9932 - val_loss: 0.0396\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9978 - loss: 0.0142 - val_accuracy: 0.9932 - val_loss: 0.0265\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9978 - loss: 0.0117 - val_accuracy: 0.9932 - val_loss: 0.0188\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 625ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 0 49  0]\n",
            " [ 0  1 45]]\n",
            "Precision: 0.9933, Recall: 0.9928, Accuracy: 0.9932, F1 Score: 0.9930\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.3241 - loss: 1.1241 - val_accuracy: 0.3493 - val_loss: 1.1058\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 3s/step - accuracy: 0.3513 - loss: 1.1212 - val_accuracy: 0.3836 - val_loss: 1.1009\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.2991 - loss: 1.1045 - val_accuracy: 0.3151 - val_loss: 1.1073\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.3287 - loss: 1.1118 - val_accuracy: 0.3151 - val_loss: 1.1013\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.3153 - loss: 1.1038 - val_accuracy: 0.3151 - val_loss: 1.0985\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.3261 - loss: 1.0978 - val_accuracy: 0.3493 - val_loss: 1.0955\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.3635 - loss: 1.1015 - val_accuracy: 0.4041 - val_loss: 1.0974\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.3503 - loss: 1.0985 - val_accuracy: 0.4178 - val_loss: 1.0915\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.3460 - loss: 1.0931 - val_accuracy: 0.4315 - val_loss: 1.0716\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.4444 - loss: 1.0552 - val_accuracy: 0.4521 - val_loss: 1.0251\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.5165 - loss: 0.9575 - val_accuracy: 0.5411 - val_loss: 0.9617\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.5702 - loss: 0.8766 - val_accuracy: 0.6233 - val_loss: 0.8205\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.6982 - loss: 0.7234 - val_accuracy: 0.6986 - val_loss: 0.7508\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.7336 - loss: 0.6371 - val_accuracy: 0.6849 - val_loss: 0.6776\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8181 - loss: 0.4776 - val_accuracy: 0.7466 - val_loss: 0.6003\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8314 - loss: 0.3979 - val_accuracy: 0.7603 - val_loss: 0.5220\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9116 - loss: 0.2845 - val_accuracy: 0.7877 - val_loss: 0.4613\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9277 - loss: 0.2354 - val_accuracy: 0.8699 - val_loss: 0.3966\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9189 - loss: 0.2267 - val_accuracy: 0.8699 - val_loss: 0.2968\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9475 - loss: 0.1545 - val_accuracy: 0.9247 - val_loss: 0.2039\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9709 - loss: 0.1011 - val_accuracy: 0.9110 - val_loss: 0.2571\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.9763 - loss: 0.0760 - val_accuracy: 0.9247 - val_loss: 0.2484\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9847 - loss: 0.0469 - val_accuracy: 0.9521 - val_loss: 0.1589\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9885 - loss: 0.0378 - val_accuracy: 0.9589 - val_loss: 0.1440\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9934 - loss: 0.0259 - val_accuracy: 0.9589 - val_loss: 0.1947\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9913 - loss: 0.0305 - val_accuracy: 0.9589 - val_loss: 0.1399\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9955 - loss: 0.0171 - val_accuracy: 0.9658 - val_loss: 0.1528\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9521 - val_loss: 0.2015\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9964 - loss: 0.0083 - val_accuracy: 0.9589 - val_loss: 0.2045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e1816c09bc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 658ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e1816c09bc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 931ms/step\n",
            "Confusion Matrix:\n",
            "[[49  0  2]\n",
            " [ 2 47  0]\n",
            " [ 0  2 44]]\n",
            "Precision: 0.9588, Recall: 0.9588, Accuracy: 0.9589, F1 Score: 0.9588\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {0: 51, 1: 48, 2: 47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 3s/step - accuracy: 0.3332 - loss: 1.1205 - val_accuracy: 0.3493 - val_loss: 1.0978\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.3022 - loss: 1.1089 - val_accuracy: 0.4384 - val_loss: 1.0911\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.3668 - loss: 1.0916 - val_accuracy: 0.5068 - val_loss: 1.0569\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.4634 - loss: 1.0336 - val_accuracy: 0.6507 - val_loss: 0.8140\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.5974 - loss: 0.8659 - val_accuracy: 0.6849 - val_loss: 0.6914\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.7304 - loss: 0.7107 - val_accuracy: 0.7329 - val_loss: 0.6048\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.8116 - loss: 0.5229 - val_accuracy: 0.9178 - val_loss: 0.2398\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.9083 - loss: 0.2842 - val_accuracy: 0.9247 - val_loss: 0.2188\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9508 - loss: 0.1745 - val_accuracy: 0.9521 - val_loss: 0.1749\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9780 - loss: 0.1070 - val_accuracy: 0.9795 - val_loss: 0.0966\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9634 - loss: 0.1615 - val_accuracy: 0.8767 - val_loss: 0.4049\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.9360 - loss: 0.2402 - val_accuracy: 0.9726 - val_loss: 0.1241\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9738 - loss: 0.1175 - val_accuracy: 0.9863 - val_loss: 0.0717\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9729 - loss: 0.1173 - val_accuracy: 0.9932 - val_loss: 0.0686\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9884 - loss: 0.0500 - val_accuracy: 0.9863 - val_loss: 0.0735\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0224 - val_accuracy: 0.9863 - val_loss: 0.0747\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.9843 - loss: 0.0359 - val_accuracy: 0.9863 - val_loss: 0.0652\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.9871 - loss: 0.0460 - val_accuracy: 0.9932 - val_loss: 0.0786\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9944 - loss: 0.0276 - val_accuracy: 0.9932 - val_loss: 0.0682\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0107 - val_accuracy: 0.9932 - val_loss: 0.0662\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 640ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 1 46  1]\n",
            " [ 0  0 47]]\n",
            "Precision: 0.9866, Recall: 0.9861, Accuracy: 0.9863, F1 Score: 0.9862\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {0: 51, 1: 48, 2: 47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.3388 - loss: 1.1255 - val_accuracy: 0.3219 - val_loss: 1.1005\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.3073 - loss: 1.1159 - val_accuracy: 0.3493 - val_loss: 1.0971\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.3503 - loss: 1.0984 - val_accuracy: 0.3699 - val_loss: 1.0871\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.4485 - loss: 1.0801 - val_accuracy: 0.4110 - val_loss: 1.0619\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.4399 - loss: 1.0527 - val_accuracy: 0.5274 - val_loss: 0.9893\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.5782 - loss: 0.8936 - val_accuracy: 0.5616 - val_loss: 0.8622\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.7187 - loss: 0.7142 - val_accuracy: 0.7260 - val_loss: 0.6783\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.8379 - loss: 0.4345 - val_accuracy: 0.8151 - val_loss: 0.4699\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9148 - loss: 0.3230 - val_accuracy: 0.8356 - val_loss: 0.5303\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.9174 - loss: 0.2538 - val_accuracy: 0.8082 - val_loss: 0.6681\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9154 - loss: 0.3002 - val_accuracy: 0.9384 - val_loss: 0.2141\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.9490 - loss: 0.1500 - val_accuracy: 0.8219 - val_loss: 0.6174\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9137 - loss: 0.2937 - val_accuracy: 0.9110 - val_loss: 0.2269\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9734 - loss: 0.1053 - val_accuracy: 0.9452 - val_loss: 0.2316\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 644ms/step\n",
            "Confusion Matrix:\n",
            "[[48  3  0]\n",
            " [ 5 43  0]\n",
            " [ 0  1 46]]\n",
            "Precision: 0.9402, Recall: 0.9386, Accuracy: 0.9384, F1 Score: 0.9392\n",
            "\n",
            "=== 5-Fold Cross-Validation Summary ===\n",
            "Avg Precision: 0.9720\n",
            "Avg Recall:    0.9712\n",
            "Avg Accuracy:  0.9712\n",
            "Avg F1 Score:  0.9714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 3s/step - accuracy: 0.3801 - loss: 1.0946 - val_accuracy: 0.2521 - val_loss: 1.0910\n",
            "Epoch 2/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 3s/step - accuracy: 0.5222 - loss: 0.9439 - val_accuracy: 0.9096 - val_loss: 0.2946\n",
            "Epoch 3/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 3s/step - accuracy: 0.9199 - loss: 0.2547 - val_accuracy: 0.9808 - val_loss: 0.0734\n",
            "Epoch 4/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 3s/step - accuracy: 0.9820 - loss: 0.0792 - val_accuracy: 0.9863 - val_loss: 0.0429\n",
            "Epoch 5/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 0.9922 - loss: 0.0289 - val_accuracy: 0.9945 - val_loss: 0.0133\n",
            "Epoch 6/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 0.9992 - loss: 0.0053 - val_accuracy: 0.9945 - val_loss: 0.0084\n",
            "Epoch 7/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9945 - val_loss: 0.0072\n",
            "Epoch 8/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9945 - val_loss: 0.0063\n",
            "Epoch 9/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9973 - val_loss: 0.0060\n",
            "Epoch 10/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
            "Epoch 11/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
            "Epoch 12/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
            "Epoch 13/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
            "Epoch 14/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
            "Epoch 15/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 3s/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
            "Epoch 16/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 9.8387e-04 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
            "Epoch 17/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
            "Epoch 18/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 9.3875e-04 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
            "Epoch 19/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 9.5172e-04 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
            "Epoch 20/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 8.9706e-04 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
            "Epoch 21/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 9.2766e-04 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
            "Epoch 22/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
            "Epoch 23/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 8.6494e-04 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
            "Epoch 24/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 8.3160e-04 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
            "Epoch 26/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 9.4095e-04 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
            "Epoch 27/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 8.2799e-04 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
            "Epoch 28/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 7.7402e-04 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
            "Epoch 29/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 7.6191e-04 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
            "Epoch 30/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 7.9544e-04 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 926ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "Confusion Matrix:\n",
            "[[50  0  0]\n",
            " [ 0 49  0]\n",
            " [ 0  0 46]]\n",
            "Test Accuracy:  1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall:    1.0000\n",
            "Test F1 Score:  1.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import TimeDistributed, Reshape, LSTM\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load data from Google Drive\n",
        "def import_data(base_path, class_names, img_height=224, img_width=224):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_folder = os.path.join(base_path, class_name)\n",
        "        for img_name in os.listdir(class_folder):\n",
        "            img_path = os.path.join(class_folder, img_name)\n",
        "            try:\n",
        "                img = load_img(img_path, target_size=(img_height, img_width))\n",
        "                img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
        "                images.append(img_array)\n",
        "                labels.append(class_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Define CNN model\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Reshape((54, 54*64)),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile with Adam optimizer\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Main\n",
        "base_path = '/content/drive/My Drive/mbpose/holdingSquat'\n",
        "class_names = ['Incorrect_low', 'Correct', 'Incorrect_high']\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "# Load data\n",
        "x, y = import_data(base_path, class_names, img_height, img_width)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Create 6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train, x_val = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Class weights for imbalance\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    # Create model\n",
        "    model = create_cnn_lstm_model(input_shape=(img_height, img_width, 3), num_classes=num_classes)\n",
        "\n",
        "    # Early stopping\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train\n",
        "    model.fit(\n",
        "        x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val),\n",
        "        verbose=1, class_weight=class_weights, callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    predictions = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, predictions, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, predictions, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    f1 = f1_score(y_val, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, predictions))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "# Report average scores\n",
        "print(\"\\n=== 5-Fold Cross-Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "\n",
        "# === Final Testing on Fold 6 ===\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "test_index = test_fold[1]\n",
        "x_train, x_test = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train final model\n",
        "final_model = create_cnn_lstm_model(input_shape=(img_height, img_width, 3), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "final_model.fit(\n",
        "    x_train, y_train, epochs=30, batch_size=32, validation_split=0.1,\n",
        "    class_weight=class_weights, callbacks=[early_stop], verbose=1\n",
        ")\n",
        "\n",
        "# Final test evaluation\n",
        "test_predictions = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "test_f1 = f1_score(y_test, test_predictions, average='macro', zero_division=0)\n",
        "test_precision = precision_score(y_test, test_predictions, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_predictions, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, test_predictions))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x-4JijhLEFY"
      },
      "source": [
        "(2) Training by using CNN-LSTM via keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HF9VbMnrEU2",
        "outputId": "b27ce241-1fe7-4f60-e591-753e5deaf43a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.3381 - loss: 1.0986 - val_accuracy: 0.4726 - val_loss: 1.0915\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4016 - loss: 1.0900 - val_accuracy: 0.5068 - val_loss: 1.0605\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4931 - loss: 1.0440 - val_accuracy: 0.5342 - val_loss: 0.9472\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5528 - loss: 0.9628 - val_accuracy: 0.5205 - val_loss: 0.9202\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5635 - loss: 0.9367 - val_accuracy: 0.6027 - val_loss: 0.8647\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5889 - loss: 0.9194 - val_accuracy: 0.6301 - val_loss: 0.8515\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6333 - loss: 0.8733 - val_accuracy: 0.6712 - val_loss: 0.7784\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6749 - loss: 0.7946 - val_accuracy: 0.7055 - val_loss: 0.7154\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7169 - loss: 0.7068 - val_accuracy: 0.7740 - val_loss: 0.6191\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7634 - loss: 0.5995 - val_accuracy: 0.8699 - val_loss: 0.5109\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8288 - loss: 0.4974 - val_accuracy: 0.8699 - val_loss: 0.4256\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8474 - loss: 0.4306 - val_accuracy: 0.8356 - val_loss: 0.4241\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8490 - loss: 0.4138 - val_accuracy: 0.9452 - val_loss: 0.2857\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9284 - loss: 0.2961 - val_accuracy: 0.9247 - val_loss: 0.2512\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9117 - loss: 0.2548 - val_accuracy: 0.9178 - val_loss: 0.2383\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9342 - loss: 0.2382 - val_accuracy: 0.9521 - val_loss: 0.1677\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9523 - loss: 0.1955 - val_accuracy: 0.9110 - val_loss: 0.2375\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1757 - val_accuracy: 0.9315 - val_loss: 0.2045\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9471 - loss: 0.1783 - val_accuracy: 0.9452 - val_loss: 0.1324\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: 0.1692 - val_accuracy: 0.9658 - val_loss: 0.0799\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9758 - loss: 0.1192 - val_accuracy: 0.9589 - val_loss: 0.0952\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9543 - loss: 0.1486 - val_accuracy: 0.9726 - val_loss: 0.0891\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9853 - loss: 0.1012 - val_accuracy: 0.9863 - val_loss: 0.0630\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9652 - loss: 0.1124 - val_accuracy: 0.9110 - val_loss: 0.2064\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9538 - loss: 0.1448 - val_accuracy: 0.9863 - val_loss: 0.0643\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9800 - loss: 0.0750 - val_accuracy: 0.9863 - val_loss: 0.0508\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0802 - val_accuracy: 0.9863 - val_loss: 0.0461\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0968 - val_accuracy: 0.9932 - val_loss: 0.0322\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0624 - val_accuracy: 0.9795 - val_loss: 0.0475\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0831 - val_accuracy: 0.9932 - val_loss: 0.0328\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 0 49  0]\n",
            " [ 0  1 45]]\n",
            "Precision: 0.9933, Recall: 0.9928, Accuracy: 0.9932, F1 Score: 0.9930\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.3588 - loss: 1.0996 - val_accuracy: 0.3493 - val_loss: 1.0958\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3451 - loss: 1.0988 - val_accuracy: 0.3493 - val_loss: 1.0889\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4020 - loss: 1.0796 - val_accuracy: 0.3767 - val_loss: 1.0563\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4554 - loss: 1.0370 - val_accuracy: 0.6027 - val_loss: 0.9316\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5431 - loss: 0.9814 - val_accuracy: 0.5959 - val_loss: 0.8949\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5362 - loss: 0.9493 - val_accuracy: 0.6438 - val_loss: 0.8715\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5485 - loss: 0.9327 - val_accuracy: 0.5616 - val_loss: 0.8791\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5415 - loss: 0.9225 - val_accuracy: 0.6096 - val_loss: 0.8464\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5669 - loss: 0.9207 - val_accuracy: 0.6301 - val_loss: 0.8257\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5696 - loss: 0.8900 - val_accuracy: 0.6438 - val_loss: 0.7961\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5918 - loss: 0.8738 - val_accuracy: 0.6575 - val_loss: 0.7640\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6074 - loss: 0.8324 - val_accuracy: 0.6849 - val_loss: 0.7251\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6401 - loss: 0.7896 - val_accuracy: 0.7808 - val_loss: 0.6485\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6822 - loss: 0.7293 - val_accuracy: 0.7260 - val_loss: 0.6045\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7167 - loss: 0.6712 - val_accuracy: 0.8082 - val_loss: 0.4928\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7886 - loss: 0.5555 - val_accuracy: 0.8767 - val_loss: 0.4075\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8078 - loss: 0.4759 - val_accuracy: 0.8836 - val_loss: 0.3735\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8363 - loss: 0.4532 - val_accuracy: 0.8219 - val_loss: 0.3973\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8726 - loss: 0.3684 - val_accuracy: 0.9041 - val_loss: 0.2838\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8770 - loss: 0.3561 - val_accuracy: 0.9041 - val_loss: 0.2472\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9120 - loss: 0.2841 - val_accuracy: 0.8836 - val_loss: 0.2722\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8884 - loss: 0.2869 - val_accuracy: 0.9384 - val_loss: 0.1729\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9066 - loss: 0.2528 - val_accuracy: 0.9247 - val_loss: 0.1961\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9228 - loss: 0.2696 - val_accuracy: 0.9384 - val_loss: 0.1609\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9209 - loss: 0.2301 - val_accuracy: 0.9041 - val_loss: 0.1792\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9446 - loss: 0.2251 - val_accuracy: 0.9521 - val_loss: 0.1447\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9399 - loss: 0.2153 - val_accuracy: 0.9384 - val_loss: 0.1275\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9477 - loss: 0.1638 - val_accuracy: 0.9658 - val_loss: 0.1004\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9617 - loss: 0.1599 - val_accuracy: 0.9589 - val_loss: 0.1060\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9609 - loss: 0.1361 - val_accuracy: 0.9726 - val_loss: 0.1046\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 1 48  0]\n",
            " [ 0  4 42]]\n",
            "Precision: 0.9679, Recall: 0.9642, Accuracy: 0.9658, F1 Score: 0.9651\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.3028 - loss: 1.0992 - val_accuracy: 0.5479 - val_loss: 1.0887\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4444 - loss: 1.0852 - val_accuracy: 0.5274 - val_loss: 1.0545\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4767 - loss: 1.0375 - val_accuracy: 0.5548 - val_loss: 0.9220\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5291 - loss: 0.9786 - val_accuracy: 0.6438 - val_loss: 0.9012\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5510 - loss: 0.9227 - val_accuracy: 0.5616 - val_loss: 0.9056\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5589 - loss: 0.9157 - val_accuracy: 0.5411 - val_loss: 0.9241\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5891 - loss: 0.8857 - val_accuracy: 0.5342 - val_loss: 0.8859\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6204 - loss: 0.8426 - val_accuracy: 0.5479 - val_loss: 0.8766\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6268 - loss: 0.8406 - val_accuracy: 0.6096 - val_loss: 0.8700\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6472 - loss: 0.8130 - val_accuracy: 0.6301 - val_loss: 0.7915\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6940 - loss: 0.7386 - val_accuracy: 0.7534 - val_loss: 0.7164\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7141 - loss: 0.6749 - val_accuracy: 0.7397 - val_loss: 0.7027\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7375 - loss: 0.6483 - val_accuracy: 0.7808 - val_loss: 0.5533\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7834 - loss: 0.5514 - val_accuracy: 0.8151 - val_loss: 0.4865\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7911 - loss: 0.5208 - val_accuracy: 0.7603 - val_loss: 0.5362\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7425 - loss: 0.5331 - val_accuracy: 0.7877 - val_loss: 0.4311\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8413 - loss: 0.4117 - val_accuracy: 0.8493 - val_loss: 0.3551\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8476 - loss: 0.3696 - val_accuracy: 0.8904 - val_loss: 0.3280\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8694 - loss: 0.3498 - val_accuracy: 0.8630 - val_loss: 0.3258\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8268 - loss: 0.3639 - val_accuracy: 0.9041 - val_loss: 0.2883\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8645 - loss: 0.3308 - val_accuracy: 0.9315 - val_loss: 0.2521\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8783 - loss: 0.3118 - val_accuracy: 0.9247 - val_loss: 0.2383\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8769 - loss: 0.3077 - val_accuracy: 0.8630 - val_loss: 0.2685\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9154 - loss: 0.2503 - val_accuracy: 0.8836 - val_loss: 0.2263\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9253 - loss: 0.2080 - val_accuracy: 0.9658 - val_loss: 0.1612\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9496 - loss: 0.1683 - val_accuracy: 0.9726 - val_loss: 0.1198\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9585 - loss: 0.1419 - val_accuracy: 0.9726 - val_loss: 0.1125\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.1148 - val_accuracy: 0.9932 - val_loss: 0.0606\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9706 - loss: 0.1079 - val_accuracy: 0.9795 - val_loss: 0.0708\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 0.0815 - val_accuracy: 0.9384 - val_loss: 0.1305\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 0 49  0]\n",
            " [ 0  1 45]]\n",
            "Precision: 0.9933, Recall: 0.9928, Accuracy: 0.9932, F1 Score: 0.9930\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {0: 51, 1: 48, 2: 47}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.3332 - loss: 1.0972 - val_accuracy: 0.4863 - val_loss: 1.0894\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3869 - loss: 1.0906 - val_accuracy: 0.5411 - val_loss: 1.0700\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4653 - loss: 1.0596 - val_accuracy: 0.4589 - val_loss: 1.0498\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5527 - loss: 0.9818 - val_accuracy: 0.4658 - val_loss: 0.9553\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5522 - loss: 0.9354 - val_accuracy: 0.5342 - val_loss: 0.9298\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5830 - loss: 0.9191 - val_accuracy: 0.5137 - val_loss: 0.9555\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6120 - loss: 0.9039 - val_accuracy: 0.5479 - val_loss: 0.9067\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6031 - loss: 0.8909 - val_accuracy: 0.5274 - val_loss: 0.9145\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6249 - loss: 0.8630 - val_accuracy: 0.5753 - val_loss: 0.8519\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5758 - loss: 0.8902 - val_accuracy: 0.5000 - val_loss: 0.9364\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6602 - loss: 0.8142 - val_accuracy: 0.6575 - val_loss: 0.7437\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6125 - loss: 0.8108 - val_accuracy: 0.5822 - val_loss: 0.7798\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6977 - loss: 0.6679 - val_accuracy: 0.7877 - val_loss: 0.5643\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7699 - loss: 0.5890 - val_accuracy: 0.8288 - val_loss: 0.4640\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8215 - loss: 0.4951 - val_accuracy: 0.8699 - val_loss: 0.3723\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8745 - loss: 0.4024 - val_accuracy: 0.9041 - val_loss: 0.2981\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8876 - loss: 0.3212 - val_accuracy: 0.9315 - val_loss: 0.2386\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9229 - loss: 0.2490 - val_accuracy: 0.9452 - val_loss: 0.1809\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9451 - loss: 0.1843 - val_accuracy: 0.9452 - val_loss: 0.1999\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9152 - loss: 0.2076 - val_accuracy: 0.9247 - val_loss: 0.1830\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9492 - loss: 0.1466 - val_accuracy: 0.9521 - val_loss: 0.1497\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9764 - loss: 0.1186 - val_accuracy: 0.9589 - val_loss: 0.1214\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9734 - loss: 0.1070 - val_accuracy: 0.9658 - val_loss: 0.0859\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9765 - loss: 0.0888 - val_accuracy: 0.9795 - val_loss: 0.0754\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0720 - val_accuracy: 0.9726 - val_loss: 0.0783\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.0699 - val_accuracy: 0.9863 - val_loss: 0.0586\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0629 - val_accuracy: 0.9726 - val_loss: 0.0852\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0591 - val_accuracy: 0.9726 - val_loss: 0.0582\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9815 - loss: 0.0609 - val_accuracy: 0.9795 - val_loss: 0.0557\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0428 - val_accuracy: 0.9795 - val_loss: 0.0474\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 1 47  0]\n",
            " [ 0  2 45]]\n",
            "Precision: 0.9800, Recall: 0.9789, Accuracy: 0.9795, F1 Score: 0.9792\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {0: 50, 1: 48, 2: 47}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.3257 - loss: 1.0985 - val_accuracy: 0.3241 - val_loss: 1.0948\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3866 - loss: 1.0888 - val_accuracy: 0.3586 - val_loss: 1.0689\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4779 - loss: 1.0538 - val_accuracy: 0.5862 - val_loss: 0.9671\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4990 - loss: 0.9997 - val_accuracy: 0.5862 - val_loss: 0.9502\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5767 - loss: 0.9260 - val_accuracy: 0.6069 - val_loss: 0.9170\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5678 - loss: 0.9072 - val_accuracy: 0.6069 - val_loss: 0.9079\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5231 - loss: 0.9499 - val_accuracy: 0.5931 - val_loss: 0.8960\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5914 - loss: 0.8774 - val_accuracy: 0.6276 - val_loss: 0.8649\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5937 - loss: 0.8864 - val_accuracy: 0.5655 - val_loss: 0.8587\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5970 - loss: 0.8428 - val_accuracy: 0.6276 - val_loss: 0.8159\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6180 - loss: 0.8144 - val_accuracy: 0.6414 - val_loss: 0.7861\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6556 - loss: 0.8106 - val_accuracy: 0.6966 - val_loss: 0.7193\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6889 - loss: 0.7237 - val_accuracy: 0.7379 - val_loss: 0.6508\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6986 - loss: 0.7192 - val_accuracy: 0.7310 - val_loss: 0.6101\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7318 - loss: 0.6285 - val_accuracy: 0.8276 - val_loss: 0.5244\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8099 - loss: 0.5254 - val_accuracy: 0.8897 - val_loss: 0.4047\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8344 - loss: 0.4305 - val_accuracy: 0.9379 - val_loss: 0.3323\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8612 - loss: 0.3925 - val_accuracy: 0.9241 - val_loss: 0.2758\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9266 - loss: 0.2845 - val_accuracy: 0.9724 - val_loss: 0.2047\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9526 - loss: 0.2030 - val_accuracy: 0.9517 - val_loss: 0.1715\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9501 - loss: 0.1842 - val_accuracy: 0.9655 - val_loss: 0.1421\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9566 - loss: 0.1511 - val_accuracy: 0.9724 - val_loss: 0.1070\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9652 - loss: 0.1307 - val_accuracy: 0.9793 - val_loss: 0.0871\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.0988 - val_accuracy: 0.9862 - val_loss: 0.0737\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9846 - loss: 0.0732 - val_accuracy: 0.9793 - val_loss: 0.0785\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9746 - loss: 0.0738 - val_accuracy: 0.9793 - val_loss: 0.0582\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0620 - val_accuracy: 0.9862 - val_loss: 0.0477\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0457 - val_accuracy: 0.9862 - val_loss: 0.0512\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0402 - val_accuracy: 0.9862 - val_loss: 0.0451\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9923 - loss: 0.0447 - val_accuracy: 0.9931 - val_loss: 0.0383\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Confusion Matrix:\n",
            "[[50  0  0]\n",
            " [ 0 47  1]\n",
            " [ 0  0 47]]\n",
            "Precision: 0.9931, Recall: 0.9931, Accuracy: 0.9931, F1 Score: 0.9930\n",
            "\n",
            "=== 5-Fold Cross-Validation Summary ===\n",
            "Avg Precision: 0.9855\n",
            "Avg Recall:    0.9843\n",
            "Avg Accuracy:  0.9849\n",
            "Avg F1 Score:  0.9846\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.4109 - loss: 1.0672 - val_accuracy: 0.5151 - val_loss: 0.9483\n",
            "Epoch 2/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5701 - loss: 0.9020 - val_accuracy: 0.5808 - val_loss: 0.8673\n",
            "Epoch 3/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6221 - loss: 0.8255 - val_accuracy: 0.6356 - val_loss: 0.7834\n",
            "Epoch 4/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6662 - loss: 0.7421 - val_accuracy: 0.6438 - val_loss: 0.7131\n",
            "Epoch 5/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7394 - loss: 0.6188 - val_accuracy: 0.8164 - val_loss: 0.4358\n",
            "Epoch 6/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8481 - loss: 0.4154 - val_accuracy: 0.9233 - val_loss: 0.2639\n",
            "Epoch 7/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8990 - loss: 0.2810 - val_accuracy: 0.9315 - val_loss: 0.1861\n",
            "Epoch 8/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9233 - loss: 0.2046 - val_accuracy: 0.9562 - val_loss: 0.1213\n",
            "Epoch 9/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1395 - val_accuracy: 0.9836 - val_loss: 0.0871\n",
            "Epoch 10/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.1150 - val_accuracy: 0.9836 - val_loss: 0.0740\n",
            "Epoch 11/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9755 - loss: 0.0843 - val_accuracy: 0.9890 - val_loss: 0.0411\n",
            "Epoch 12/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0628 - val_accuracy: 0.9918 - val_loss: 0.0264\n",
            "Epoch 13/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9878 - loss: 0.0435 - val_accuracy: 0.9945 - val_loss: 0.0212\n",
            "Epoch 14/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9873 - loss: 0.0398 - val_accuracy: 0.9918 - val_loss: 0.0288\n",
            "Epoch 15/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9823 - loss: 0.0538 - val_accuracy: 0.9753 - val_loss: 0.0596\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "[[51  0  0]\n",
            " [ 0 48  0]\n",
            " [ 0  0 46]]\n",
            "Test Accuracy:  1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall:    1.0000\n",
            "Test F1 Score:  1.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load and return features and labels\n",
        "def import_data():\n",
        "    data = pd.read_csv('mergedshuffledHoldingSquatV2keypoints.csv')\n",
        "    x = data.iloc[:, :-1].values\n",
        "    y = data['correct'].astype(int).values\n",
        "    y = np.searchsorted(np.unique(y), y)  # Make sure y is 0-based index\n",
        "    return x, y\n",
        "\n",
        "# Define the CNN-LSTM model\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main\n",
        "x, y = import_data()\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "#6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train_raw, x_val_raw = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Fit scaler only on training data\n",
        "    scaler = MinMaxScaler()\n",
        "    x_train = scaler.fit_transform(x_train_raw)\n",
        "    x_val = scaler.transform(x_val_raw)\n",
        "\n",
        "    # Reshape for CNN input\n",
        "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    # Class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Train model\n",
        "    model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "              validation_data=(x_val, y_val),\n",
        "              class_weight=class_weights,\n",
        "              callbacks=[early_stop],\n",
        "              verbose=1)\n",
        "\n",
        "    # Evaluate\n",
        "    preds = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, preds, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, preds))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "# Report average scores\n",
        "print(\"\\n=== 5-Fold Cross-Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "\n",
        "#Testing on Fold 6\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "test_index = test_fold[1]\n",
        "x_train_raw, x_test_raw = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Refit scaler only on training data\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train_raw)\n",
        "x_test = scaler.transform(x_test_raw)\n",
        "\n",
        "# Reshape for CNN input\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train Fold 6 with early stopping\n",
        "final_model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "final_model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "                validation_split=0.1, class_weight=class_weights,\n",
        "                callbacks=[early_stop], verbose=1)\n",
        "\n",
        "# Final test evaluation\n",
        "test_preds = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_preds)\n",
        "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
        "test_precision = precision_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import joblib\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load and return features and labels\n",
        "def import_data():\n",
        "    data = pd.read_csv('mergedshuffledHoldingSquatV2keypoints.csv')\n",
        "    x = data.iloc[:, :-1].values\n",
        "    y = data['correct'].astype(int).values\n",
        "    y = np.searchsorted(np.unique(y), y)  # Make sure y is 0-based index\n",
        "    return x, y\n",
        "\n",
        "# Define the CNN-LSTM model\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main\n",
        "x, y = import_data()\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "#6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "\n",
        "# Variables to track the best model\n",
        "best_f1_score = -float('inf')\n",
        "best_model = None\n",
        "best_scaler = None\n",
        "best_fold = 0\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train_raw, x_val_raw = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Fit scaler only on training data\n",
        "    scaler = MinMaxScaler()\n",
        "    x_train = scaler.fit_transform(x_train_raw)\n",
        "    x_val = scaler.transform(x_val_raw)\n",
        "\n",
        "    # Reshape for CNN input\n",
        "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    # Class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Train model\n",
        "    model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "              validation_data=(x_val, y_val),\n",
        "              class_weight=class_weights,\n",
        "              callbacks=[early_stop],\n",
        "              verbose=1)\n",
        "\n",
        "    # Evaluate\n",
        "    preds = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, preds, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, preds))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "\n",
        "    # Save the best model based on F1 score\n",
        "    if f1 > best_f1_score:\n",
        "        best_f1_score = f1\n",
        "        best_model = model\n",
        "        best_scaler = scaler\n",
        "        best_fold = fold_index\n",
        "        # Save the best model and scaler\n",
        "        model.save('best_model.keras')\n",
        "        joblib.dump(scaler, 'best_scaler.pkl')\n",
        "        print(f\"Saved best model and scaler from Fold {fold_index} with F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Report average scores\n",
        "print(\"\\n=== 5-Fold Cross-Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "\n",
        "#Testing on Fold 6\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "test_index = test_fold[1]\n",
        "x_train_raw, x_test_raw = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Refit scaler only on training data\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train_raw)\n",
        "x_test = scaler.transform(x_test_raw)\n",
        "\n",
        "# Reshape for CNN input\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train Fold 6 with early stopping\n",
        "final_model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "final_model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "                validation_split=0.1, class_weight=class_weights,\n",
        "                callbacks=[early_stop], verbose=1)\n",
        "\n",
        "# Final test evaluation\n",
        "test_preds = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_preds)\n",
        "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
        "test_precision = precision_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"\\n=== Best Model Summary ===\")\n",
        "print(f\"Best model is from Fold {best_fold} with F1 Score: {best_f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSULn4fQyZn6",
        "outputId": "d53ceec7-f7e3-4c37-a58e-d3e4eb45d765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.3381 - loss: 1.0986 - val_accuracy: 0.4726 - val_loss: 1.0915\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4016 - loss: 1.0900 - val_accuracy: 0.5068 - val_loss: 1.0605\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4931 - loss: 1.0440 - val_accuracy: 0.5342 - val_loss: 0.9472\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5528 - loss: 0.9628 - val_accuracy: 0.5205 - val_loss: 0.9202\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5635 - loss: 0.9367 - val_accuracy: 0.6027 - val_loss: 0.8647\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5889 - loss: 0.9194 - val_accuracy: 0.6301 - val_loss: 0.8515\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6333 - loss: 0.8733 - val_accuracy: 0.6712 - val_loss: 0.7784\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6749 - loss: 0.7946 - val_accuracy: 0.7055 - val_loss: 0.7154\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7169 - loss: 0.7068 - val_accuracy: 0.7740 - val_loss: 0.6191\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7634 - loss: 0.5995 - val_accuracy: 0.8699 - val_loss: 0.5109\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8288 - loss: 0.4974 - val_accuracy: 0.8699 - val_loss: 0.4256\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8474 - loss: 0.4306 - val_accuracy: 0.8356 - val_loss: 0.4241\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8490 - loss: 0.4138 - val_accuracy: 0.9452 - val_loss: 0.2857\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9284 - loss: 0.2961 - val_accuracy: 0.9247 - val_loss: 0.2512\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9117 - loss: 0.2548 - val_accuracy: 0.9178 - val_loss: 0.2383\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9342 - loss: 0.2382 - val_accuracy: 0.9521 - val_loss: 0.1677\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9523 - loss: 0.1955 - val_accuracy: 0.9110 - val_loss: 0.2375\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9545 - loss: 0.1757 - val_accuracy: 0.9315 - val_loss: 0.2045\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9471 - loss: 0.1783 - val_accuracy: 0.9452 - val_loss: 0.1324\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9645 - loss: 0.1692 - val_accuracy: 0.9658 - val_loss: 0.0799\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9758 - loss: 0.1192 - val_accuracy: 0.9589 - val_loss: 0.0952\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9543 - loss: 0.1486 - val_accuracy: 0.9726 - val_loss: 0.0891\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9853 - loss: 0.1012 - val_accuracy: 0.9863 - val_loss: 0.0630\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: 0.1124 - val_accuracy: 0.9110 - val_loss: 0.2064\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9538 - loss: 0.1448 - val_accuracy: 0.9863 - val_loss: 0.0643\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9800 - loss: 0.0750 - val_accuracy: 0.9863 - val_loss: 0.0508\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0802 - val_accuracy: 0.9863 - val_loss: 0.0461\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9835 - loss: 0.0968 - val_accuracy: 0.9932 - val_loss: 0.0322\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.0624 - val_accuracy: 0.9795 - val_loss: 0.0475\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9902 - loss: 0.0831 - val_accuracy: 0.9932 - val_loss: 0.0328\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 0 49  0]\n",
            " [ 0  1 45]]\n",
            "Precision: 0.9933, Recall: 0.9928, Accuracy: 0.9932, F1 Score: 0.9930\n",
            "Saved best model and scaler from Fold 1 with F1 Score: 0.9930\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.3588 - loss: 1.0996 - val_accuracy: 0.3493 - val_loss: 1.0958\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3451 - loss: 1.0988 - val_accuracy: 0.3493 - val_loss: 1.0889\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4020 - loss: 1.0796 - val_accuracy: 0.3767 - val_loss: 1.0563\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4554 - loss: 1.0370 - val_accuracy: 0.6027 - val_loss: 0.9316\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5431 - loss: 0.9814 - val_accuracy: 0.5959 - val_loss: 0.8949\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5362 - loss: 0.9493 - val_accuracy: 0.6438 - val_loss: 0.8715\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5485 - loss: 0.9327 - val_accuracy: 0.5616 - val_loss: 0.8791\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5415 - loss: 0.9225 - val_accuracy: 0.6096 - val_loss: 0.8464\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5669 - loss: 0.9207 - val_accuracy: 0.6301 - val_loss: 0.8257\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5696 - loss: 0.8900 - val_accuracy: 0.6438 - val_loss: 0.7961\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5918 - loss: 0.8738 - val_accuracy: 0.6575 - val_loss: 0.7640\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6074 - loss: 0.8324 - val_accuracy: 0.6849 - val_loss: 0.7251\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6401 - loss: 0.7896 - val_accuracy: 0.7808 - val_loss: 0.6485\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6822 - loss: 0.7293 - val_accuracy: 0.7260 - val_loss: 0.6045\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7167 - loss: 0.6712 - val_accuracy: 0.8082 - val_loss: 0.4928\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7886 - loss: 0.5555 - val_accuracy: 0.8767 - val_loss: 0.4075\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8078 - loss: 0.4759 - val_accuracy: 0.8836 - val_loss: 0.3735\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8363 - loss: 0.4532 - val_accuracy: 0.8219 - val_loss: 0.3973\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8726 - loss: 0.3684 - val_accuracy: 0.9041 - val_loss: 0.2838\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8770 - loss: 0.3561 - val_accuracy: 0.9041 - val_loss: 0.2472\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9120 - loss: 0.2841 - val_accuracy: 0.8836 - val_loss: 0.2722\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8884 - loss: 0.2869 - val_accuracy: 0.9384 - val_loss: 0.1729\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9066 - loss: 0.2528 - val_accuracy: 0.9247 - val_loss: 0.1961\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9228 - loss: 0.2696 - val_accuracy: 0.9384 - val_loss: 0.1609\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9209 - loss: 0.2301 - val_accuracy: 0.9041 - val_loss: 0.1792\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9446 - loss: 0.2251 - val_accuracy: 0.9521 - val_loss: 0.1447\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9399 - loss: 0.2153 - val_accuracy: 0.9384 - val_loss: 0.1275\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9477 - loss: 0.1638 - val_accuracy: 0.9658 - val_loss: 0.1004\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9617 - loss: 0.1599 - val_accuracy: 0.9589 - val_loss: 0.1060\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9609 - loss: 0.1361 - val_accuracy: 0.9726 - val_loss: 0.1046\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 1 48  0]\n",
            " [ 0  4 42]]\n",
            "Precision: 0.9679, Recall: 0.9642, Accuracy: 0.9658, F1 Score: 0.9651\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {0: 51, 1: 49, 2: 46}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.3028 - loss: 1.0992 - val_accuracy: 0.5479 - val_loss: 1.0887\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4444 - loss: 1.0852 - val_accuracy: 0.5274 - val_loss: 1.0545\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4767 - loss: 1.0375 - val_accuracy: 0.5548 - val_loss: 0.9220\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5291 - loss: 0.9786 - val_accuracy: 0.6438 - val_loss: 0.9012\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5510 - loss: 0.9227 - val_accuracy: 0.5616 - val_loss: 0.9056\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5589 - loss: 0.9157 - val_accuracy: 0.5411 - val_loss: 0.9241\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5891 - loss: 0.8857 - val_accuracy: 0.5342 - val_loss: 0.8859\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6204 - loss: 0.8426 - val_accuracy: 0.5479 - val_loss: 0.8766\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6268 - loss: 0.8406 - val_accuracy: 0.6096 - val_loss: 0.8700\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6472 - loss: 0.8130 - val_accuracy: 0.6301 - val_loss: 0.7915\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6940 - loss: 0.7386 - val_accuracy: 0.7534 - val_loss: 0.7164\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7141 - loss: 0.6749 - val_accuracy: 0.7397 - val_loss: 0.7027\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7375 - loss: 0.6483 - val_accuracy: 0.7808 - val_loss: 0.5533\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7834 - loss: 0.5514 - val_accuracy: 0.8151 - val_loss: 0.4865\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7911 - loss: 0.5208 - val_accuracy: 0.7603 - val_loss: 0.5362\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7425 - loss: 0.5331 - val_accuracy: 0.7877 - val_loss: 0.4311\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8413 - loss: 0.4117 - val_accuracy: 0.8493 - val_loss: 0.3551\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8476 - loss: 0.3696 - val_accuracy: 0.8904 - val_loss: 0.3280\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8694 - loss: 0.3498 - val_accuracy: 0.8630 - val_loss: 0.3258\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8268 - loss: 0.3639 - val_accuracy: 0.9041 - val_loss: 0.2883\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8645 - loss: 0.3308 - val_accuracy: 0.9315 - val_loss: 0.2521\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8783 - loss: 0.3118 - val_accuracy: 0.9247 - val_loss: 0.2383\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8769 - loss: 0.3077 - val_accuracy: 0.8630 - val_loss: 0.2685\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9154 - loss: 0.2503 - val_accuracy: 0.8836 - val_loss: 0.2263\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9253 - loss: 0.2080 - val_accuracy: 0.9658 - val_loss: 0.1612\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9496 - loss: 0.1683 - val_accuracy: 0.9726 - val_loss: 0.1198\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9585 - loss: 0.1419 - val_accuracy: 0.9726 - val_loss: 0.1125\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9803 - loss: 0.1148 - val_accuracy: 0.9932 - val_loss: 0.0606\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9706 - loss: 0.1079 - val_accuracy: 0.9795 - val_loss: 0.0708\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9865 - loss: 0.0815 - val_accuracy: 0.9384 - val_loss: 0.1305\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 0 49  0]\n",
            " [ 0  1 45]]\n",
            "Precision: 0.9933, Recall: 0.9928, Accuracy: 0.9932, F1 Score: 0.9930\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {0: 51, 1: 48, 2: 47}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.3332 - loss: 1.0972 - val_accuracy: 0.4863 - val_loss: 1.0894\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3869 - loss: 1.0906 - val_accuracy: 0.5411 - val_loss: 1.0700\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4653 - loss: 1.0596 - val_accuracy: 0.4589 - val_loss: 1.0498\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5527 - loss: 0.9818 - val_accuracy: 0.4658 - val_loss: 0.9553\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5522 - loss: 0.9354 - val_accuracy: 0.5342 - val_loss: 0.9298\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5830 - loss: 0.9191 - val_accuracy: 0.5137 - val_loss: 0.9555\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6120 - loss: 0.9039 - val_accuracy: 0.5479 - val_loss: 0.9067\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6031 - loss: 0.8909 - val_accuracy: 0.5274 - val_loss: 0.9145\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6249 - loss: 0.8630 - val_accuracy: 0.5753 - val_loss: 0.8519\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5758 - loss: 0.8902 - val_accuracy: 0.5000 - val_loss: 0.9364\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6602 - loss: 0.8142 - val_accuracy: 0.6575 - val_loss: 0.7437\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6125 - loss: 0.8108 - val_accuracy: 0.5822 - val_loss: 0.7798\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6977 - loss: 0.6679 - val_accuracy: 0.7877 - val_loss: 0.5643\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7699 - loss: 0.5890 - val_accuracy: 0.8288 - val_loss: 0.4640\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8215 - loss: 0.4951 - val_accuracy: 0.8699 - val_loss: 0.3723\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8745 - loss: 0.4024 - val_accuracy: 0.9041 - val_loss: 0.2981\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8876 - loss: 0.3212 - val_accuracy: 0.9315 - val_loss: 0.2386\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9229 - loss: 0.2490 - val_accuracy: 0.9452 - val_loss: 0.1809\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9451 - loss: 0.1843 - val_accuracy: 0.9452 - val_loss: 0.1999\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9152 - loss: 0.2076 - val_accuracy: 0.9247 - val_loss: 0.1830\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9492 - loss: 0.1466 - val_accuracy: 0.9521 - val_loss: 0.1497\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9764 - loss: 0.1186 - val_accuracy: 0.9589 - val_loss: 0.1214\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9734 - loss: 0.1070 - val_accuracy: 0.9658 - val_loss: 0.0859\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9765 - loss: 0.0888 - val_accuracy: 0.9795 - val_loss: 0.0754\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9842 - loss: 0.0720 - val_accuracy: 0.9726 - val_loss: 0.0783\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9882 - loss: 0.0699 - val_accuracy: 0.9863 - val_loss: 0.0586\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9845 - loss: 0.0629 - val_accuracy: 0.9726 - val_loss: 0.0852\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9825 - loss: 0.0591 - val_accuracy: 0.9726 - val_loss: 0.0582\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9815 - loss: 0.0609 - val_accuracy: 0.9795 - val_loss: 0.0557\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9892 - loss: 0.0428 - val_accuracy: 0.9795 - val_loss: 0.0474\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 1 47  0]\n",
            " [ 0  2 45]]\n",
            "Precision: 0.9800, Recall: 0.9789, Accuracy: 0.9795, F1 Score: 0.9792\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {0: 50, 1: 48, 2: 47}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.3257 - loss: 1.0985 - val_accuracy: 0.3241 - val_loss: 1.0948\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3866 - loss: 1.0888 - val_accuracy: 0.3586 - val_loss: 1.0689\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4779 - loss: 1.0538 - val_accuracy: 0.5862 - val_loss: 0.9671\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4990 - loss: 0.9997 - val_accuracy: 0.5862 - val_loss: 0.9502\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5767 - loss: 0.9260 - val_accuracy: 0.6069 - val_loss: 0.9170\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5678 - loss: 0.9072 - val_accuracy: 0.6069 - val_loss: 0.9079\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5231 - loss: 0.9499 - val_accuracy: 0.5931 - val_loss: 0.8960\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5914 - loss: 0.8774 - val_accuracy: 0.6276 - val_loss: 0.8649\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5937 - loss: 0.8864 - val_accuracy: 0.5655 - val_loss: 0.8587\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5970 - loss: 0.8428 - val_accuracy: 0.6276 - val_loss: 0.8159\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6180 - loss: 0.8144 - val_accuracy: 0.6414 - val_loss: 0.7861\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6556 - loss: 0.8106 - val_accuracy: 0.6966 - val_loss: 0.7193\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6889 - loss: 0.7237 - val_accuracy: 0.7379 - val_loss: 0.6508\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6986 - loss: 0.7192 - val_accuracy: 0.7310 - val_loss: 0.6101\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7318 - loss: 0.6285 - val_accuracy: 0.8276 - val_loss: 0.5244\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8099 - loss: 0.5254 - val_accuracy: 0.8897 - val_loss: 0.4047\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8344 - loss: 0.4305 - val_accuracy: 0.9379 - val_loss: 0.3323\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8612 - loss: 0.3925 - val_accuracy: 0.9241 - val_loss: 0.2758\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9266 - loss: 0.2845 - val_accuracy: 0.9724 - val_loss: 0.2047\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9526 - loss: 0.2030 - val_accuracy: 0.9517 - val_loss: 0.1715\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9501 - loss: 0.1842 - val_accuracy: 0.9655 - val_loss: 0.1421\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9566 - loss: 0.1511 - val_accuracy: 0.9724 - val_loss: 0.1070\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9652 - loss: 0.1307 - val_accuracy: 0.9793 - val_loss: 0.0871\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9773 - loss: 0.0988 - val_accuracy: 0.9862 - val_loss: 0.0737\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0732 - val_accuracy: 0.9793 - val_loss: 0.0785\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9746 - loss: 0.0738 - val_accuracy: 0.9793 - val_loss: 0.0582\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9890 - loss: 0.0620 - val_accuracy: 0.9862 - val_loss: 0.0477\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9893 - loss: 0.0457 - val_accuracy: 0.9862 - val_loss: 0.0512\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9941 - loss: 0.0402 - val_accuracy: 0.9862 - val_loss: 0.0451\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9923 - loss: 0.0447 - val_accuracy: 0.9931 - val_loss: 0.0383\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
            "Confusion Matrix:\n",
            "[[50  0  0]\n",
            " [ 0 47  1]\n",
            " [ 0  0 47]]\n",
            "Precision: 0.9931, Recall: 0.9931, Accuracy: 0.9931, F1 Score: 0.9930\n",
            "Saved best model and scaler from Fold 5 with F1 Score: 0.9930\n",
            "\n",
            "=== 5-Fold Cross-Validation Summary ===\n",
            "Avg Precision: 0.9855\n",
            "Avg Recall:    0.9843\n",
            "Avg Accuracy:  0.9849\n",
            "Avg F1 Score:  0.9846\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4109 - loss: 1.0672 - val_accuracy: 0.5151 - val_loss: 0.9483\n",
            "Epoch 2/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5701 - loss: 0.9020 - val_accuracy: 0.5808 - val_loss: 0.8673\n",
            "Epoch 3/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6221 - loss: 0.8255 - val_accuracy: 0.6356 - val_loss: 0.7834\n",
            "Epoch 4/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6662 - loss: 0.7421 - val_accuracy: 0.6438 - val_loss: 0.7131\n",
            "Epoch 5/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7394 - loss: 0.6188 - val_accuracy: 0.8164 - val_loss: 0.4358\n",
            "Epoch 6/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8481 - loss: 0.4154 - val_accuracy: 0.9233 - val_loss: 0.2639\n",
            "Epoch 7/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8990 - loss: 0.2810 - val_accuracy: 0.9315 - val_loss: 0.1861\n",
            "Epoch 8/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9233 - loss: 0.2046 - val_accuracy: 0.9562 - val_loss: 0.1213\n",
            "Epoch 9/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9565 - loss: 0.1395 - val_accuracy: 0.9836 - val_loss: 0.0871\n",
            "Epoch 10/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9601 - loss: 0.1150 - val_accuracy: 0.9836 - val_loss: 0.0740\n",
            "Epoch 11/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9755 - loss: 0.0843 - val_accuracy: 0.9890 - val_loss: 0.0411\n",
            "Epoch 12/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0628 - val_accuracy: 0.9918 - val_loss: 0.0264\n",
            "Epoch 13/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.0435 - val_accuracy: 0.9945 - val_loss: 0.0212\n",
            "Epoch 14/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0398 - val_accuracy: 0.9918 - val_loss: 0.0288\n",
            "Epoch 15/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0538 - val_accuracy: 0.9753 - val_loss: 0.0596\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "[[51  0  0]\n",
            " [ 0 48  0]\n",
            " [ 0  0 46]]\n",
            "Test Accuracy:  1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall:    1.0000\n",
            "Test F1 Score:  1.0000\n",
            "\n",
            "=== Best Model Summary ===\n",
            "Best model is from Fold 5 with F1 Score: 0.9930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OegaBxEeLEVA"
      },
      "source": [
        "(3) Training by using CNN-LSTM via keypoints + augmetation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GudcigIrEkPt",
        "outputId": "c0f50006-736d-4c8b-b5c9-3137fb62aeb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced class distribution:\n",
            "1    305\n",
            "2    305\n",
            "0    305\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {1: 51, 2: 51, 0: 51}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 33ms/step - accuracy: 0.3043 - loss: 1.0987 - val_accuracy: 0.5033 - val_loss: 1.0902\n",
            "Epoch 2/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4384 - loss: 1.0854 - val_accuracy: 0.4837 - val_loss: 1.0424\n",
            "Epoch 3/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5187 - loss: 1.0086 - val_accuracy: 0.5556 - val_loss: 0.9509\n",
            "Epoch 4/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5629 - loss: 0.9325 - val_accuracy: 0.5882 - val_loss: 0.9289\n",
            "Epoch 5/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5732 - loss: 0.9215 - val_accuracy: 0.5425 - val_loss: 0.9302\n",
            "Epoch 6/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5959 - loss: 0.9042 - val_accuracy: 0.5490 - val_loss: 0.9354\n",
            "Epoch 7/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5929 - loss: 0.9022 - val_accuracy: 0.5948 - val_loss: 0.9142\n",
            "Epoch 8/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5984 - loss: 0.8728 - val_accuracy: 0.6013 - val_loss: 0.8733\n",
            "Epoch 9/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5959 - loss: 0.8489 - val_accuracy: 0.6275 - val_loss: 0.8178\n",
            "Epoch 10/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6418 - loss: 0.7997 - val_accuracy: 0.6863 - val_loss: 0.7523\n",
            "Epoch 11/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6660 - loss: 0.7459 - val_accuracy: 0.7320 - val_loss: 0.7069\n",
            "Epoch 12/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6952 - loss: 0.7118 - val_accuracy: 0.7516 - val_loss: 0.6811\n",
            "Epoch 13/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7447 - loss: 0.6560 - val_accuracy: 0.7778 - val_loss: 0.6052\n",
            "Epoch 14/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7472 - loss: 0.5694 - val_accuracy: 0.7582 - val_loss: 0.5844\n",
            "Epoch 15/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7789 - loss: 0.5647 - val_accuracy: 0.8366 - val_loss: 0.4742\n",
            "Epoch 16/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8039 - loss: 0.4943 - val_accuracy: 0.8627 - val_loss: 0.4170\n",
            "Epoch 17/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8127 - loss: 0.4650 - val_accuracy: 0.9216 - val_loss: 0.3839\n",
            "Epoch 18/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8366 - loss: 0.4329 - val_accuracy: 0.9216 - val_loss: 0.3166\n",
            "Epoch 19/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8485 - loss: 0.3823 - val_accuracy: 0.8235 - val_loss: 0.3977\n",
            "Epoch 20/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8546 - loss: 0.3598 - val_accuracy: 0.7843 - val_loss: 0.4863\n",
            "Epoch 21/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8574 - loss: 0.3714 - val_accuracy: 0.8170 - val_loss: 0.3437\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Confusion Matrix:\n",
            "[[50  1  0]\n",
            " [ 2 49  0]\n",
            " [ 0  9 42]]\n",
            "Precision: 0.9307, Recall: 0.9216, Accuracy: 0.9216, F1 Score: 0.9217\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {2: 51, 1: 51, 0: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.3208 - loss: 1.0999 - val_accuracy: 0.5098 - val_loss: 1.0901\n",
            "Epoch 2/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4086 - loss: 1.0909 - val_accuracy: 0.3922 - val_loss: 1.0674\n",
            "Epoch 3/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4525 - loss: 1.0578 - val_accuracy: 0.6144 - val_loss: 0.9601\n",
            "Epoch 4/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4568 - loss: 1.0389 - val_accuracy: 0.5817 - val_loss: 0.9445\n",
            "Epoch 5/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5544 - loss: 0.9476 - val_accuracy: 0.6340 - val_loss: 0.9198\n",
            "Epoch 6/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5287 - loss: 0.9691 - val_accuracy: 0.6013 - val_loss: 0.8743\n",
            "Epoch 7/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5474 - loss: 0.9104 - val_accuracy: 0.5621 - val_loss: 0.8838\n",
            "Epoch 8/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5494 - loss: 0.9309 - val_accuracy: 0.6275 - val_loss: 0.8453\n",
            "Epoch 9/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5753 - loss: 0.8941 - val_accuracy: 0.6275 - val_loss: 0.8307\n",
            "Epoch 10/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5702 - loss: 0.9007 - val_accuracy: 0.6209 - val_loss: 0.8219\n",
            "Epoch 11/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5980 - loss: 0.8740 - val_accuracy: 0.6275 - val_loss: 0.8105\n",
            "Epoch 12/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5816 - loss: 0.8580 - val_accuracy: 0.6536 - val_loss: 0.7633\n",
            "Epoch 13/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6069 - loss: 0.8222 - val_accuracy: 0.7190 - val_loss: 0.7225\n",
            "Epoch 14/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6628 - loss: 0.7681 - val_accuracy: 0.7647 - val_loss: 0.6202\n",
            "Epoch 15/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7016 - loss: 0.7249 - val_accuracy: 0.7843 - val_loss: 0.5511\n",
            "Epoch 16/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7243 - loss: 0.6504 - val_accuracy: 0.8824 - val_loss: 0.4472\n",
            "Epoch 17/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7671 - loss: 0.5526 - val_accuracy: 0.8693 - val_loss: 0.4068\n",
            "Epoch 18/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7812 - loss: 0.5276 - val_accuracy: 0.9020 - val_loss: 0.3314\n",
            "Epoch 19/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8090 - loss: 0.4696 - val_accuracy: 0.9020 - val_loss: 0.3210\n",
            "Epoch 20/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8526 - loss: 0.3952 - val_accuracy: 0.9085 - val_loss: 0.2472\n",
            "Epoch 21/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8376 - loss: 0.3708 - val_accuracy: 0.9412 - val_loss: 0.1985\n",
            "Epoch 22/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8774 - loss: 0.3027 - val_accuracy: 0.9542 - val_loss: 0.1697\n",
            "Epoch 23/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8882 - loss: 0.2833 - val_accuracy: 0.9608 - val_loss: 0.1620\n",
            "Epoch 24/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9240 - loss: 0.2488 - val_accuracy: 0.9673 - val_loss: 0.1440\n",
            "Epoch 25/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8890 - loss: 0.2918 - val_accuracy: 0.9608 - val_loss: 0.1568\n",
            "Epoch 26/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8996 - loss: 0.2732 - val_accuracy: 0.9673 - val_loss: 0.1389\n",
            "Epoch 27/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9207 - loss: 0.2366 - val_accuracy: 0.9739 - val_loss: 0.1117\n",
            "Epoch 28/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9316 - loss: 0.1938 - val_accuracy: 0.9739 - val_loss: 0.0929\n",
            "Epoch 29/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9488 - loss: 0.1550 - val_accuracy: 0.9739 - val_loss: 0.0968\n",
            "Epoch 30/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9492 - loss: 0.1632 - val_accuracy: 0.9739 - val_loss: 0.0916\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 0 51  0]\n",
            " [ 0  4 47]]\n",
            "Precision: 0.9758, Recall: 0.9739, Accuracy: 0.9739, F1 Score: 0.9738\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {2: 51, 1: 51, 0: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.3456 - loss: 1.0981 - val_accuracy: 0.3725 - val_loss: 1.0900\n",
            "Epoch 2/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4551 - loss: 1.0825 - val_accuracy: 0.4641 - val_loss: 1.0398\n",
            "Epoch 3/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5344 - loss: 1.0026 - val_accuracy: 0.4967 - val_loss: 0.9600\n",
            "Epoch 4/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5814 - loss: 0.9271 - val_accuracy: 0.6013 - val_loss: 0.9093\n",
            "Epoch 5/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6210 - loss: 0.8674 - val_accuracy: 0.5556 - val_loss: 0.8962\n",
            "Epoch 6/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6189 - loss: 0.8727 - val_accuracy: 0.6013 - val_loss: 0.8811\n",
            "Epoch 7/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6178 - loss: 0.8530 - val_accuracy: 0.6078 - val_loss: 0.8519\n",
            "Epoch 8/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6507 - loss: 0.8245 - val_accuracy: 0.6340 - val_loss: 0.8038\n",
            "Epoch 9/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6837 - loss: 0.8045 - val_accuracy: 0.6863 - val_loss: 0.7571\n",
            "Epoch 10/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6803 - loss: 0.7113 - val_accuracy: 0.7712 - val_loss: 0.6593\n",
            "Epoch 11/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7350 - loss: 0.6615 - val_accuracy: 0.7778 - val_loss: 0.5957\n",
            "Epoch 12/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7627 - loss: 0.5618 - val_accuracy: 0.8693 - val_loss: 0.4650\n",
            "Epoch 13/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7670 - loss: 0.5357 - val_accuracy: 0.8105 - val_loss: 0.4467\n",
            "Epoch 14/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8264 - loss: 0.4628 - val_accuracy: 0.8039 - val_loss: 0.4990\n",
            "Epoch 15/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8558 - loss: 0.4169 - val_accuracy: 0.8105 - val_loss: 0.4398\n",
            "Epoch 16/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8603 - loss: 0.3857 - val_accuracy: 0.8170 - val_loss: 0.4051\n",
            "Epoch 17/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8792 - loss: 0.3358 - val_accuracy: 0.8105 - val_loss: 0.3772\n",
            "Epoch 18/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8717 - loss: 0.3435 - val_accuracy: 0.7974 - val_loss: 0.4645\n",
            "Epoch 19/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8611 - loss: 0.3703 - val_accuracy: 0.9346 - val_loss: 0.2907\n",
            "Epoch 20/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8886 - loss: 0.3237 - val_accuracy: 0.9085 - val_loss: 0.2678\n",
            "Epoch 21/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8869 - loss: 0.2979 - val_accuracy: 0.8301 - val_loss: 0.3799\n",
            "Epoch 22/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8803 - loss: 0.3003 - val_accuracy: 0.9085 - val_loss: 0.2597\n",
            "Epoch 23/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8806 - loss: 0.3141 - val_accuracy: 0.9020 - val_loss: 0.2406\n",
            "Epoch 24/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9169 - loss: 0.2434 - val_accuracy: 0.9281 - val_loss: 0.2087\n",
            "Epoch 25/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9102 - loss: 0.2416 - val_accuracy: 0.9216 - val_loss: 0.2111\n",
            "Epoch 26/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8960 - loss: 0.2653 - val_accuracy: 0.9412 - val_loss: 0.1813\n",
            "Epoch 27/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9456 - loss: 0.1928 - val_accuracy: 0.9542 - val_loss: 0.1519\n",
            "Epoch 28/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9148 - loss: 0.2414 - val_accuracy: 0.9542 - val_loss: 0.1445\n",
            "Epoch 29/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9413 - loss: 0.1715 - val_accuracy: 0.9608 - val_loss: 0.1403\n",
            "Epoch 30/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9438 - loss: 0.1677 - val_accuracy: 0.9608 - val_loss: 0.1225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d5d10f8ccc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d5d10f8ccc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Confusion Matrix:\n",
            "[[50  1  0]\n",
            " [ 0 50  1]\n",
            " [ 0  4 47]]\n",
            "Precision: 0.9628, Recall: 0.9608, Accuracy: 0.9608, F1 Score: 0.9610\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {1: 51, 2: 51, 0: 50}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.3348 - loss: 1.0962 - val_accuracy: 0.4803 - val_loss: 1.0825\n",
            "Epoch 2/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4279 - loss: 1.0780 - val_accuracy: 0.5592 - val_loss: 1.0155\n",
            "Epoch 3/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4803 - loss: 1.0246 - val_accuracy: 0.5132 - val_loss: 0.9278\n",
            "Epoch 4/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5284 - loss: 0.9792 - val_accuracy: 0.5789 - val_loss: 0.8839\n",
            "Epoch 5/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5500 - loss: 0.9225 - val_accuracy: 0.5658 - val_loss: 0.8992\n",
            "Epoch 6/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5542 - loss: 0.9097 - val_accuracy: 0.6053 - val_loss: 0.8275\n",
            "Epoch 7/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5835 - loss: 0.8869 - val_accuracy: 0.6316 - val_loss: 0.8418\n",
            "Epoch 8/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5953 - loss: 0.8602 - val_accuracy: 0.6250 - val_loss: 0.7947\n",
            "Epoch 9/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6213 - loss: 0.8294 - val_accuracy: 0.6711 - val_loss: 0.6980\n",
            "Epoch 10/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6632 - loss: 0.7937 - val_accuracy: 0.7303 - val_loss: 0.6110\n",
            "Epoch 11/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7178 - loss: 0.6452 - val_accuracy: 0.7237 - val_loss: 0.5495\n",
            "Epoch 12/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7361 - loss: 0.5858 - val_accuracy: 0.8618 - val_loss: 0.4252\n",
            "Epoch 13/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7761 - loss: 0.4991 - val_accuracy: 0.8750 - val_loss: 0.3869\n",
            "Epoch 14/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8720 - loss: 0.4002 - val_accuracy: 0.8618 - val_loss: 0.3218\n",
            "Epoch 15/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8354 - loss: 0.3847 - val_accuracy: 0.9079 - val_loss: 0.2934\n",
            "Epoch 16/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8828 - loss: 0.3366 - val_accuracy: 0.8092 - val_loss: 0.4124\n",
            "Epoch 17/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8458 - loss: 0.3438 - val_accuracy: 0.9211 - val_loss: 0.2204\n",
            "Epoch 18/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9241 - loss: 0.2598 - val_accuracy: 0.9276 - val_loss: 0.2040\n",
            "Epoch 19/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9299 - loss: 0.2135 - val_accuracy: 0.9342 - val_loss: 0.1823\n",
            "Epoch 20/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9340 - loss: 0.2022 - val_accuracy: 0.9145 - val_loss: 0.2358\n",
            "Epoch 21/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9361 - loss: 0.2022 - val_accuracy: 0.9211 - val_loss: 0.2042\n",
            "Epoch 22/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9463 - loss: 0.1910 - val_accuracy: 0.9342 - val_loss: 0.2052\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Confusion Matrix:\n",
            "[[49  1  0]\n",
            " [ 0 43  8]\n",
            " [ 0  1 50]]\n",
            "Precision: 0.9392, Recall: 0.9345, Accuracy: 0.9342, F1 Score: 0.9344\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {1: 51, 0: 51, 2: 50}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.3133 - loss: 1.1004 - val_accuracy: 0.3816 - val_loss: 1.0952\n",
            "Epoch 2/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3859 - loss: 1.0897 - val_accuracy: 0.4145 - val_loss: 1.0847\n",
            "Epoch 3/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4665 - loss: 1.0586 - val_accuracy: 0.5066 - val_loss: 1.0105\n",
            "Epoch 4/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5320 - loss: 0.9539 - val_accuracy: 0.6382 - val_loss: 0.9456\n",
            "Epoch 5/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5856 - loss: 0.9057 - val_accuracy: 0.6316 - val_loss: 0.9050\n",
            "Epoch 6/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5844 - loss: 0.9105 - val_accuracy: 0.5724 - val_loss: 0.8832\n",
            "Epoch 7/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5711 - loss: 0.8948 - val_accuracy: 0.5789 - val_loss: 0.8618\n",
            "Epoch 8/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5983 - loss: 0.8602 - val_accuracy: 0.6184 - val_loss: 0.8328\n",
            "Epoch 9/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5987 - loss: 0.8517 - val_accuracy: 0.6250 - val_loss: 0.8101\n",
            "Epoch 10/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6044 - loss: 0.8598 - val_accuracy: 0.6118 - val_loss: 0.7860\n",
            "Epoch 11/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6267 - loss: 0.8253 - val_accuracy: 0.6579 - val_loss: 0.7654\n",
            "Epoch 12/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6219 - loss: 0.7891 - val_accuracy: 0.6908 - val_loss: 0.7234\n",
            "Epoch 13/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6509 - loss: 0.7791 - val_accuracy: 0.7434 - val_loss: 0.6663\n",
            "Epoch 14/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6868 - loss: 0.7228 - val_accuracy: 0.7829 - val_loss: 0.5847\n",
            "Epoch 15/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7153 - loss: 0.6795 - val_accuracy: 0.7961 - val_loss: 0.5569\n",
            "Epoch 16/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7385 - loss: 0.6269 - val_accuracy: 0.8487 - val_loss: 0.4558\n",
            "Epoch 17/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7889 - loss: 0.5298 - val_accuracy: 0.8882 - val_loss: 0.3587\n",
            "Epoch 18/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8438 - loss: 0.4405 - val_accuracy: 0.8553 - val_loss: 0.3730\n",
            "Epoch 19/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8113 - loss: 0.4715 - val_accuracy: 0.8684 - val_loss: 0.3957\n",
            "Epoch 20/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8402 - loss: 0.4426 - val_accuracy: 0.9474 - val_loss: 0.2610\n",
            "Epoch 21/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8791 - loss: 0.3407 - val_accuracy: 0.9605 - val_loss: 0.1825\n",
            "Epoch 22/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9072 - loss: 0.2727 - val_accuracy: 0.9605 - val_loss: 0.1432\n",
            "Epoch 23/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9166 - loss: 0.2377 - val_accuracy: 0.9671 - val_loss: 0.1233\n",
            "Epoch 24/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9340 - loss: 0.2107 - val_accuracy: 0.9803 - val_loss: 0.1116\n",
            "Epoch 25/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9188 - loss: 0.2139 - val_accuracy: 0.9803 - val_loss: 0.1003\n",
            "Epoch 26/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9386 - loss: 0.1765 - val_accuracy: 0.9868 - val_loss: 0.0842\n",
            "Epoch 27/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9525 - loss: 0.1546 - val_accuracy: 0.9934 - val_loss: 0.0788\n",
            "Epoch 28/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9422 - loss: 0.1590 - val_accuracy: 0.9803 - val_loss: 0.0788\n",
            "Epoch 29/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9585 - loss: 0.1393 - val_accuracy: 0.9868 - val_loss: 0.0651\n",
            "Epoch 30/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9671 - loss: 0.1197 - val_accuracy: 0.9539 - val_loss: 0.1277\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
            "Confusion Matrix:\n",
            "[[51  0  0]\n",
            " [ 1 49  1]\n",
            " [ 0  0 50]]\n",
            "Precision: 0.9871, Recall: 0.9869, Accuracy: 0.9868, F1 Score: 0.9868\n",
            "\n",
            "=== 5-Fold Validation Summary ===\n",
            "Avg Precision: 0.9591\n",
            "Avg Recall:    0.9555\n",
            "Avg Accuracy:  0.9555\n",
            "Avg F1 Score:  0.9555\n",
            "Best Fold: 5 with F1 Score: 0.9868\n",
            "Best model saved at: best_cnn_lstm_model.keras\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.3952 - loss: 1.0709 - val_accuracy: 0.5602 - val_loss: 0.9125\n",
            "Epoch 2/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5756 - loss: 0.8995 - val_accuracy: 0.6204 - val_loss: 0.8171\n",
            "Epoch 3/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6220 - loss: 0.8157 - val_accuracy: 0.7461 - val_loss: 0.6501\n",
            "Epoch 4/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7532 - loss: 0.5979 - val_accuracy: 0.8351 - val_loss: 0.4182\n",
            "Epoch 5/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8041 - loss: 0.5020 - val_accuracy: 0.8691 - val_loss: 0.3509\n",
            "Epoch 6/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8594 - loss: 0.3755 - val_accuracy: 0.8770 - val_loss: 0.3142\n",
            "Epoch 7/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8890 - loss: 0.3015 - val_accuracy: 0.9372 - val_loss: 0.2052\n",
            "Epoch 8/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.2366 - val_accuracy: 0.9450 - val_loss: 0.1719\n",
            "Epoch 9/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9183 - loss: 0.2219 - val_accuracy: 0.9503 - val_loss: 0.1477\n",
            "Epoch 10/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9346 - loss: 0.1848 - val_accuracy: 0.9660 - val_loss: 0.1183\n",
            "Epoch 11/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.1462 - val_accuracy: 0.9660 - val_loss: 0.1031\n",
            "Epoch 12/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9529 - loss: 0.1322 - val_accuracy: 0.9791 - val_loss: 0.0796\n",
            "Epoch 13/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9569 - loss: 0.1247 - val_accuracy: 0.9660 - val_loss: 0.1004\n",
            "Epoch 14/30\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9684 - loss: 0.1001 - val_accuracy: 0.9764 - val_loss: 0.0768\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "[[51  0  0]\n",
            " [ 2 47  1]\n",
            " [ 0  0 51]]\n",
            "Test Accuracy:  0.9803\n",
            "Test Precision: 0.9810\n",
            "Test Recall:    0.9800\n",
            "Test F1 Score:  0.9800\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, MaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load data\n",
        "def import_data():\n",
        "    data = pd.read_csv('mergedshuffledHoldingSquatV2keypoints.csv')\n",
        "    x = data.iloc[:, :-1].values\n",
        "    y = data['correct'].astype(int).values\n",
        "    y = np.searchsorted(np.unique(y), y)\n",
        "    scaler = MinMaxScaler()\n",
        "    x = scaler.fit_transform(x)\n",
        "    return x, y\n",
        "\n",
        "# Balance dataset using SMOTE\n",
        "def balance_data(x, y):\n",
        "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "    x_resampled, y_resampled = smote.fit_resample(x, y)\n",
        "    print(\"Balanced class distribution:\")\n",
        "    print(pd.Series(y_resampled).value_counts())\n",
        "    return x_resampled, y_resampled\n",
        "\n",
        "# Add Gaussian noise\n",
        "def augment_data(x, noise_factor=0.05):\n",
        "    noise = np.random.normal(loc=0.0, scale=noise_factor, size=x.shape)\n",
        "    return x + noise\n",
        "\n",
        "# Model definition\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main\n",
        "x, y = import_data()\n",
        "x, y = balance_data(x, y)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Create 6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "# best model\n",
        "best_model_path = \"best_cnn_lstm_model.keras\"\n",
        "best_fold, best_f1 = None, -1\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "# Perform 5-Fold\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train, x_val = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Augment training data\n",
        "    x_train = augment_data(x_train, noise_factor=0.05)\n",
        "\n",
        "    # Reshape\n",
        "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    # Class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Model & Callbacks\n",
        "    model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        validation_data=(x_val, y_val),\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    preds = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, preds, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, preds))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Save metrics\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_fold = fold_index\n",
        "        model.save(best_model_path)\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n=== 5-Fold Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "print(f\"Best Fold: {best_fold} with F1 Score: {best_f1:.4f}\")\n",
        "print(f\"Best model saved at: {best_model_path}\")\n",
        "\n",
        "# === Final Test Fold Evaluation ===\n",
        "test_index = test_fold[1]\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "x_train, x_test = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Augment and reshape\n",
        "x_train = augment_data(x_train, noise_factor=0.05)\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Final model training on Fold 6\n",
        "final_model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=2, min_delta=0.001, restore_best_weights=True)\n",
        "\n",
        "final_model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on final test set\n",
        "test_preds = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_preds)\n",
        "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
        "test_precision = precision_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}