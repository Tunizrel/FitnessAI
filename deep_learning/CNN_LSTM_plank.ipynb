{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PHdceYNod7mD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae1b22d-2558-4b7e-f9d5-7da2d10623a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Nj5voRZW9K"
      },
      "source": [
        "(1) CNN-LSTM full images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import TimeDistributed, Reshape, LSTM\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load data from Google Drive\n",
        "def import_data(base_path, class_names, img_height=224, img_width=224):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_folder = os.path.join(base_path, class_name)\n",
        "        for img_name in os.listdir(class_folder):\n",
        "            img_path = os.path.join(class_folder, img_name)\n",
        "            try:\n",
        "                img = load_img(img_path, target_size=(img_height, img_width))\n",
        "                img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
        "                images.append(img_array)\n",
        "                labels.append(class_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Define CNN model\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Reshape((54, 54*64)),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile with Adam optimizer\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Main\n",
        "base_path = '/content/drive/My Drive/mbpose/plank'\n",
        "class_names = ['Incorrect_low', 'Correct', 'Incorrect_high']\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "# Load data\n",
        "x, y = import_data(base_path, class_names, img_height, img_width)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Create 6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train, x_val = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Class weights for imbalance\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    # Create model\n",
        "    model = create_cnn_lstm_model(input_shape=(img_height, img_width, 3), num_classes=num_classes)\n",
        "\n",
        "    # Early stopping\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train\n",
        "    model.fit(\n",
        "        x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val),\n",
        "        verbose=1, class_weight=class_weights, callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    predictions = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, predictions, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, predictions, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    f1 = f1_score(y_val, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, predictions))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "# Report average scores\n",
        "print(\"\\n=== 5-Fold Cross-Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "\n",
        "# === Final Testing on Fold 6 ===\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "test_index = test_fold[1]\n",
        "x_train, x_test = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train final model\n",
        "final_model = create_cnn_lstm_model(input_shape=(img_height, img_width, 3), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "final_model.fit(\n",
        "    x_train, y_train, epochs=30, batch_size=32, validation_split=0.1,\n",
        "    class_weight=class_weights, callbacks=[early_stop], verbose=1\n",
        ")\n",
        "\n",
        "# Final test evaluation\n",
        "test_predictions = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "test_f1 = f1_score(y_test, test_predictions, average='macro', zero_division=0)\n",
        "test_precision = precision_score(y_test, test_predictions, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_predictions, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, test_predictions))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S23JGfqO6dE",
        "outputId": "f00348b8-c521-4001-9930-6eff67a8953e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {2: 58, 0: 57, 1: 53}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.3172 - loss: 1.1275 - val_accuracy: 0.3393 - val_loss: 1.0983\n",
            "Epoch 2/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.3750 - loss: 1.0903 - val_accuracy: 0.3750 - val_loss: 1.0748\n",
            "Epoch 3/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - accuracy: 0.3730 - loss: 1.0871 - val_accuracy: 0.4464 - val_loss: 1.0533\n",
            "Epoch 4/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - accuracy: 0.4678 - loss: 1.0107 - val_accuracy: 0.5536 - val_loss: 0.9413\n",
            "Epoch 5/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.5928 - loss: 0.9256 - val_accuracy: 0.5655 - val_loss: 0.8761\n",
            "Epoch 6/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.6232 - loss: 0.8438 - val_accuracy: 0.6012 - val_loss: 0.8759\n",
            "Epoch 7/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.7152 - loss: 0.7155 - val_accuracy: 0.7024 - val_loss: 0.6417\n",
            "Epoch 8/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.7594 - loss: 0.5762 - val_accuracy: 0.8452 - val_loss: 0.4977\n",
            "Epoch 9/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.8289 - loss: 0.4782 - val_accuracy: 0.8690 - val_loss: 0.3274\n",
            "Epoch 10/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.8904 - loss: 0.3046 - val_accuracy: 0.8333 - val_loss: 0.4018\n",
            "Epoch 11/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.8975 - loss: 0.3157 - val_accuracy: 0.8750 - val_loss: 0.3563\n",
            "Epoch 12/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.9235 - loss: 0.2514 - val_accuracy: 0.9107 - val_loss: 0.2454\n",
            "Epoch 13/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9367 - loss: 0.2252 - val_accuracy: 0.9345 - val_loss: 0.1930\n",
            "Epoch 14/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9665 - loss: 0.0997 - val_accuracy: 0.9286 - val_loss: 0.1898\n",
            "Epoch 15/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.9780 - loss: 0.0713 - val_accuracy: 0.8988 - val_loss: 0.2349\n",
            "Epoch 16/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9741 - loss: 0.1021 - val_accuracy: 0.8810 - val_loss: 0.3004\n",
            "Epoch 17/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.9801 - loss: 0.0767 - val_accuracy: 0.9345 - val_loss: 0.1801\n",
            "Epoch 18/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.9882 - loss: 0.0575 - val_accuracy: 0.9345 - val_loss: 0.1414\n",
            "Epoch 19/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9829 - loss: 0.0699 - val_accuracy: 0.9167 - val_loss: 0.2688\n",
            "Epoch 20/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9733 - loss: 0.0959 - val_accuracy: 0.9345 - val_loss: 0.1737\n",
            "Epoch 21/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.9846 - loss: 0.0675 - val_accuracy: 0.9524 - val_loss: 0.1283\n",
            "Epoch 22/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.9853 - loss: 0.0542 - val_accuracy: 0.9405 - val_loss: 0.1824\n",
            "Epoch 23/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.9853 - loss: 0.0454 - val_accuracy: 0.9048 - val_loss: 0.3096\n",
            "Epoch 24/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.9714 - loss: 0.0936 - val_accuracy: 0.9583 - val_loss: 0.1447\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 653ms/step\n",
            "Confusion Matrix:\n",
            "[[56  1  0]\n",
            " [ 0 49  4]\n",
            " [ 1  2 55]]\n",
            "Precision: 0.9523, Recall: 0.9518, Accuracy: 0.9524, F1 Score: 0.9520\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {2: 58, 0: 57, 1: 53}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3s/step - accuracy: 0.3318 - loss: 1.1321 - val_accuracy: 0.3274 - val_loss: 1.0999\n",
            "Epoch 2/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - accuracy: 0.3061 - loss: 1.0988 - val_accuracy: 0.3393 - val_loss: 1.0980\n",
            "Epoch 3/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.3462 - loss: 1.0943 - val_accuracy: 0.3810 - val_loss: 1.0847\n",
            "Epoch 4/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.3908 - loss: 1.0845 - val_accuracy: 0.4226 - val_loss: 1.0160\n",
            "Epoch 5/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.4582 - loss: 1.0335 - val_accuracy: 0.6190 - val_loss: 0.8998\n",
            "Epoch 6/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.5476 - loss: 0.9802 - val_accuracy: 0.6488 - val_loss: 0.8369\n",
            "Epoch 7/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.6154 - loss: 0.8704 - val_accuracy: 0.7500 - val_loss: 0.6310\n",
            "Epoch 8/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.7268 - loss: 0.6709 - val_accuracy: 0.7917 - val_loss: 0.5908\n",
            "Epoch 9/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.7974 - loss: 0.5195 - val_accuracy: 0.8095 - val_loss: 0.5177\n",
            "Epoch 10/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8677 - loss: 0.4176 - val_accuracy: 0.8274 - val_loss: 0.4869\n",
            "Epoch 11/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.9044 - loss: 0.3164 - val_accuracy: 0.8571 - val_loss: 0.3934\n",
            "Epoch 12/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.9362 - loss: 0.2160 - val_accuracy: 0.8690 - val_loss: 0.3989\n",
            "Epoch 13/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - accuracy: 0.9317 - loss: 0.2292 - val_accuracy: 0.8810 - val_loss: 0.3000\n",
            "Epoch 14/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.9545 - loss: 0.1538 - val_accuracy: 0.9286 - val_loss: 0.2223\n",
            "Epoch 15/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9824 - loss: 0.0768 - val_accuracy: 0.9286 - val_loss: 0.2068\n",
            "Epoch 16/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9776 - loss: 0.0778 - val_accuracy: 0.9167 - val_loss: 0.3022\n",
            "Epoch 17/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9439 - loss: 0.1897 - val_accuracy: 0.8929 - val_loss: 0.2862\n",
            "Epoch 18/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9470 - loss: 0.1697 - val_accuracy: 0.9048 - val_loss: 0.2677\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 857ms/step\n",
            "Confusion Matrix:\n",
            "[[52  5  0]\n",
            " [ 0 50  3]\n",
            " [ 0  4 54]]\n",
            "Precision: 0.9316, Recall: 0.9289, Accuracy: 0.9286, F1 Score: 0.9287\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {2: 58, 0: 57, 1: 53}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.3564 - loss: 1.1682 - val_accuracy: 0.3393 - val_loss: 1.0989\n",
            "Epoch 2/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.3327 - loss: 1.0989 - val_accuracy: 0.3631 - val_loss: 1.0923\n",
            "Epoch 3/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.3623 - loss: 1.0890 - val_accuracy: 0.3869 - val_loss: 1.0548\n",
            "Epoch 4/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.4073 - loss: 1.0457 - val_accuracy: 0.5238 - val_loss: 0.9125\n",
            "Epoch 5/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.5266 - loss: 0.9785 - val_accuracy: 0.4345 - val_loss: 0.9873\n",
            "Epoch 6/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.5381 - loss: 0.9674 - val_accuracy: 0.6905 - val_loss: 0.7813\n",
            "Epoch 7/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.6718 - loss: 0.7687 - val_accuracy: 0.5714 - val_loss: 0.8089\n",
            "Epoch 8/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.6784 - loss: 0.7740 - val_accuracy: 0.7738 - val_loss: 0.5211\n",
            "Epoch 9/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.7514 - loss: 0.5998 - val_accuracy: 0.7738 - val_loss: 0.5090\n",
            "Epoch 10/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.7650 - loss: 0.6089 - val_accuracy: 0.7798 - val_loss: 0.4632\n",
            "Epoch 11/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8135 - loss: 0.4612 - val_accuracy: 0.8155 - val_loss: 0.4967\n",
            "Epoch 12/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.8760 - loss: 0.3447 - val_accuracy: 0.8452 - val_loss: 0.3459\n",
            "Epoch 13/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.8892 - loss: 0.3077 - val_accuracy: 0.8690 - val_loss: 0.3112\n",
            "Epoch 14/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.9151 - loss: 0.2499 - val_accuracy: 0.9226 - val_loss: 0.1966\n",
            "Epoch 15/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9707 - loss: 0.1228 - val_accuracy: 0.9464 - val_loss: 0.1768\n",
            "Epoch 16/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9791 - loss: 0.1088 - val_accuracy: 0.9524 - val_loss: 0.1979\n",
            "Epoch 17/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9696 - loss: 0.1085 - val_accuracy: 0.9048 - val_loss: 0.2808\n",
            "Epoch 18/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9722 - loss: 0.1189 - val_accuracy: 0.9286 - val_loss: 0.2049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7923f378fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step\n",
            "Confusion Matrix:\n",
            "[[55  2  0]\n",
            " [ 1 47  5]\n",
            " [ 0  1 57]]\n",
            "Precision: 0.9472, Recall: 0.9448, Accuracy: 0.9464, F1 Score: 0.9454\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {2: 58, 0: 56, 1: 54}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3s/step - accuracy: 0.3326 - loss: 1.1431 - val_accuracy: 0.3333 - val_loss: 1.1001\n",
            "Epoch 2/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - accuracy: 0.3725 - loss: 1.0975 - val_accuracy: 0.3571 - val_loss: 1.0930\n",
            "Epoch 3/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.3877 - loss: 1.0841 - val_accuracy: 0.4643 - val_loss: 1.0671\n",
            "Epoch 4/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.4841 - loss: 1.0442 - val_accuracy: 0.5119 - val_loss: 1.0061\n",
            "Epoch 5/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - accuracy: 0.5472 - loss: 0.9698 - val_accuracy: 0.6190 - val_loss: 0.8389\n",
            "Epoch 6/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.6303 - loss: 0.8311 - val_accuracy: 0.7381 - val_loss: 0.7237\n",
            "Epoch 7/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.6938 - loss: 0.6861 - val_accuracy: 0.7917 - val_loss: 0.5884\n",
            "Epoch 8/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 0.7808 - loss: 0.5271 - val_accuracy: 0.8869 - val_loss: 0.3862\n",
            "Epoch 9/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.8970 - loss: 0.3028 - val_accuracy: 0.8512 - val_loss: 0.4128\n",
            "Epoch 10/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3s/step - accuracy: 0.9007 - loss: 0.3090 - val_accuracy: 0.8512 - val_loss: 0.3969\n",
            "Epoch 11/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8997 - loss: 0.2938 - val_accuracy: 0.9286 - val_loss: 0.1981\n",
            "Epoch 12/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9666 - loss: 0.1274 - val_accuracy: 0.8690 - val_loss: 0.4204\n",
            "Epoch 13/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.9602 - loss: 0.1546 - val_accuracy: 0.9226 - val_loss: 0.2116\n",
            "Epoch 14/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9778 - loss: 0.0963 - val_accuracy: 0.9226 - val_loss: 0.2507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x792389e777e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 664ms/step\n",
            "Confusion Matrix:\n",
            "[[56  0  0]\n",
            " [ 6 48  0]\n",
            " [ 0  6 52]]\n",
            "Precision: 0.9307, Recall: 0.9285, Accuracy: 0.9286, F1 Score: 0.9278\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {2: 58, 0: 56, 1: 54}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3s/step - accuracy: 0.3331 - loss: 1.1300 - val_accuracy: 0.3333 - val_loss: 1.0985\n",
            "Epoch 2/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.3626 - loss: 1.0965 - val_accuracy: 0.3750 - val_loss: 1.0918\n",
            "Epoch 3/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.3679 - loss: 1.0913 - val_accuracy: 0.3750 - val_loss: 1.0800\n",
            "Epoch 4/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.4060 - loss: 1.0677 - val_accuracy: 0.5060 - val_loss: 1.0285\n",
            "Epoch 5/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - accuracy: 0.5200 - loss: 0.9918 - val_accuracy: 0.5714 - val_loss: 0.9436\n",
            "Epoch 6/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.6161 - loss: 0.8740 - val_accuracy: 0.7083 - val_loss: 0.7582\n",
            "Epoch 7/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.7057 - loss: 0.6853 - val_accuracy: 0.7738 - val_loss: 0.5631\n",
            "Epoch 8/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.8030 - loss: 0.4892 - val_accuracy: 0.8095 - val_loss: 0.4924\n",
            "Epoch 9/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.8958 - loss: 0.3361 - val_accuracy: 0.8869 - val_loss: 0.3421\n",
            "Epoch 10/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 0.8861 - loss: 0.2869 - val_accuracy: 0.8810 - val_loss: 0.3592\n",
            "Epoch 11/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.9269 - loss: 0.2170 - val_accuracy: 0.8750 - val_loss: 0.3509\n",
            "Epoch 12/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9400 - loss: 0.1884 - val_accuracy: 0.9286 - val_loss: 0.2428\n",
            "Epoch 13/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.9564 - loss: 0.1401 - val_accuracy: 0.9583 - val_loss: 0.1947\n",
            "Epoch 14/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.9743 - loss: 0.0975 - val_accuracy: 0.9464 - val_loss: 0.1976\n",
            "Epoch 15/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9792 - loss: 0.0757 - val_accuracy: 0.9643 - val_loss: 0.1516\n",
            "Epoch 16/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.9812 - loss: 0.0546 - val_accuracy: 0.9702 - val_loss: 0.1444\n",
            "Epoch 17/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9948 - loss: 0.0323 - val_accuracy: 0.9821 - val_loss: 0.1218\n",
            "Epoch 18/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9765 - loss: 0.0740 - val_accuracy: 0.9167 - val_loss: 0.1943\n",
            "Epoch 19/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9730 - loss: 0.0891 - val_accuracy: 0.9643 - val_loss: 0.1640\n",
            "Epoch 20/30\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9884 - loss: 0.0508 - val_accuracy: 0.9643 - val_loss: 0.1747\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 667ms/step\n",
            "Confusion Matrix:\n",
            "[[54  1  1]\n",
            " [ 0 53  1]\n",
            " [ 0  0 58]]\n",
            "Precision: 0.9827, Recall: 0.9819, Accuracy: 0.9821, F1 Score: 0.9821\n",
            "\n",
            "=== 5-Fold Cross-Validation Summary ===\n",
            "Avg Precision: 0.9489\n",
            "Avg Recall:    0.9472\n",
            "Avg Accuracy:  0.9476\n",
            "Avg F1 Score:  0.9472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 3s/step - accuracy: 0.3907 - loss: 1.0770 - val_accuracy: 0.4714 - val_loss: 0.8672\n",
            "Epoch 2/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 3s/step - accuracy: 0.6861 - loss: 0.7036 - val_accuracy: 0.9048 - val_loss: 0.2550\n",
            "Epoch 3/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 3s/step - accuracy: 0.9252 - loss: 0.2253 - val_accuracy: 0.9381 - val_loss: 0.1750\n",
            "Epoch 4/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 3s/step - accuracy: 0.9698 - loss: 0.1114 - val_accuracy: 0.9857 - val_loss: 0.0546\n",
            "Epoch 5/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 3s/step - accuracy: 0.9622 - loss: 0.1272 - val_accuracy: 0.9929 - val_loss: 0.0331\n",
            "Epoch 6/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 3s/step - accuracy: 0.9906 - loss: 0.0251 - val_accuracy: 0.9929 - val_loss: 0.0401\n",
            "Epoch 7/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 3s/step - accuracy: 0.9981 - loss: 0.0116 - val_accuracy: 0.9929 - val_loss: 0.0223\n",
            "Epoch 8/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 3s/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.9929 - val_loss: 0.0143\n",
            "Epoch 9/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 3s/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9929 - val_loss: 0.0178\n",
            "Epoch 10/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 3s/step - accuracy: 0.9973 - loss: 0.0072 - val_accuracy: 0.9929 - val_loss: 0.0162\n",
            "Epoch 11/30\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 3s/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9929 - val_loss: 0.0183\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 962ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "Confusion Matrix:\n",
            "[[56  0  0]\n",
            " [ 0 54  0]\n",
            " [ 0  0 57]]\n",
            "Test Accuracy:  1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall:    1.0000\n",
            "Test F1 Score:  1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "HoQCI5HdZWYA",
        "outputId": "03731a50-65af-4126-9718-3f93ba262c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1 Class Distribution:\n",
            "0    55\n",
            "2    55\n",
            "1    51\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 0.3486 - loss: 1.1477 - val_accuracy: 0.3416 - val_loss: 1.0985\n",
            "Epoch 2/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.3101 - loss: 1.1096 - val_accuracy: 0.3416 - val_loss: 1.0952\n",
            "Epoch 3/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.3228 - loss: 1.1114 - val_accuracy: 0.3727 - val_loss: 1.0850\n",
            "Epoch 4/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.3644 - loss: 1.0913 - val_accuracy: 0.3789 - val_loss: 1.0641\n",
            "Epoch 5/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.4320 - loss: 1.0202 - val_accuracy: 0.5714 - val_loss: 0.9340\n",
            "Epoch 6/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.5493 - loss: 0.9140 - val_accuracy: 0.5776 - val_loss: 0.8395\n",
            "Epoch 7/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.6712 - loss: 0.7228 - val_accuracy: 0.6398 - val_loss: 0.7944\n",
            "Epoch 8/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.7493 - loss: 0.6293 - val_accuracy: 0.7205 - val_loss: 0.6276\n",
            "Epoch 9/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.7908 - loss: 0.5126 - val_accuracy: 0.8075 - val_loss: 0.4467\n",
            "Epoch 10/30\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8637 - loss: 0.3844 - val_accuracy: 0.8323 - val_loss: 0.3815\n",
            "Epoch 11/30\n",
            "\u001b[1m14/21\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9012 - loss: 0.3006"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-62a4c7dfe615>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import TimeDistributed, Reshape, LSTM\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "\n",
        "# Load data from Google Drive\n",
        "def import_data(base_path, class_names, img_height=224, img_width=224):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_folder = os.path.join(base_path, class_name)\n",
        "        for img_name in os.listdir(class_folder):\n",
        "            img_path = os.path.join(class_folder, img_name)\n",
        "            try:\n",
        "                img = load_img(img_path, target_size=(img_height, img_width))\n",
        "                img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
        "                images.append(img_array)\n",
        "                labels.append(class_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Define CNN model\n",
        "\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Reshape((54, 54*64)),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile with Adam optimizer\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "# Main\n",
        "base_path = '/content/drive/My Drive/mbpose/plank'\n",
        "class_names = ['Incorrect_low', 'Correct', 'Incorrect_high']\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "# Load data\n",
        "x, y = import_data(base_path, class_names, img_height, img_width)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Train-test split\n",
        "x_train_full, x_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    x, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_full), y=y_train_full)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "best_fold, best_f1 = None, -1\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "for fold_index, (train_index, val_index) in enumerate(skf.split(x_train_full, y_train_full), start=1):\n",
        "    x_train, x_val = x_train_full[train_index], x_train_full[val_index]\n",
        "    y_train, y_val = y_train_full[train_index], y_train_full[val_index]\n",
        "\n",
        "    print(f\"\\nFold {fold_index} Class Distribution:\")\n",
        "    print(pd.Series(y_val).value_counts())\n",
        "\n",
        "    # Create model\n",
        "    model = create_cnn_lstm_model(input_shape=(img_height, img_width, 3), num_classes=num_classes)\n",
        "\n",
        "    # Early stopping\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train\n",
        "    model.fit(\n",
        "        x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val),\n",
        "        verbose=1, class_weight=class_weights, callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    predictions = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, predictions, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, predictions, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    f1 = f1_score(y_val, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    # Confusion matrix\n",
        "    print(f\"Fold {fold_index} Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, predictions))\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_fold = fold_index\n",
        "\n",
        "# Final metrics\n",
        "print(\"\\n=== Overall Metrics ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall: {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy: {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score: {np.mean(f1_list):.4f}\")\n",
        "print(f\"Best Fold: {best_fold} with F1 Score: {best_f1:.4f}\")\n",
        "\n",
        "# Test on held-out test set\n",
        "test_predictions = np.argmax(model.predict(x_test_full), axis=1)\n",
        "print(\"\\n=== Test Set Metrics ===\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test_full, test_predictions):.4f}\")\n",
        "print(f\"Test F1 Score: {f1_score(y_test_full, test_predictions, average='macro'):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfNSAR7EZarb"
      },
      "source": [
        "(2) CNN-LSTM keypoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load and return features and labels\n",
        "def import_data():\n",
        "    data = pd.read_csv('mergedshuffledPlankV2keypoints.csv')\n",
        "    x = data.iloc[:, :-1].values\n",
        "    y = data['correct'].astype(int).values\n",
        "    y = np.searchsorted(np.unique(y), y)  # Make sure y is 0-based index\n",
        "    return x, y\n",
        "\n",
        "# Define the CNN-LSTM model\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main script\n",
        "x, y = import_data()\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Create 6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train_raw, x_val_raw = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Fit scaler only on training data\n",
        "    scaler = MinMaxScaler()\n",
        "    x_train = scaler.fit_transform(x_train_raw)\n",
        "    x_val = scaler.transform(x_val_raw)\n",
        "\n",
        "    # Reshape for CNN input\n",
        "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    # Class weights for imbalance\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Train model\n",
        "    model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "              validation_data=(x_val, y_val),\n",
        "              class_weight=class_weights,\n",
        "              callbacks=[early_stop],\n",
        "              verbose=1)\n",
        "\n",
        "    # Evaluate\n",
        "    preds = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, preds, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, preds))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "# Report average scores\n",
        "print(\"\\n=== 5-Fold Cross-Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "\n",
        "# === Final Testing on Fold 6 ===\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "test_index = test_fold[1]\n",
        "x_train_raw, x_test_raw = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Refit scaler only on training data\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train_raw)\n",
        "x_test = scaler.transform(x_test_raw)\n",
        "\n",
        "# Reshape for CNN input\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train final model (Fold 6) with stricter early stopping\n",
        "final_model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "final_model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "                validation_split=0.1, class_weight=class_weights,\n",
        "                callbacks=[early_stop], verbose=1)\n",
        "\n",
        "# Final test evaluation\n",
        "test_preds = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_preds)\n",
        "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
        "test_precision = precision_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwbk-HFCtdvU",
        "outputId": "7b04a549-b3d8-4de1-a76c-93e1c19ef202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {2: 57, 0: 54, 1: 52}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.3609 - loss: 1.0984 - val_accuracy: 0.3742 - val_loss: 1.0979\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3435 - loss: 1.0960 - val_accuracy: 0.3190 - val_loss: 1.0986\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3643 - loss: 1.0969 - val_accuracy: 0.3436 - val_loss: 1.0975\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3426 - loss: 1.0978 - val_accuracy: 0.3252 - val_loss: 1.0979\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3727 - loss: 1.0982 - val_accuracy: 0.3865 - val_loss: 1.0945\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3944 - loss: 1.0895 - val_accuracy: 0.4233 - val_loss: 1.0914\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3804 - loss: 1.0881 - val_accuracy: 0.3620 - val_loss: 1.0849\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4261 - loss: 1.0780 - val_accuracy: 0.4601 - val_loss: 1.0747\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4386 - loss: 1.0644 - val_accuracy: 0.4785 - val_loss: 1.0562\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4344 - loss: 1.0497 - val_accuracy: 0.4847 - val_loss: 1.0248\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4978 - loss: 1.0234 - val_accuracy: 0.6135 - val_loss: 0.9662\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5955 - loss: 0.9414 - val_accuracy: 0.6871 - val_loss: 0.8070\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6407 - loss: 0.8188 - val_accuracy: 0.7485 - val_loss: 0.6304\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6981 - loss: 0.6806 - val_accuracy: 0.7178 - val_loss: 0.6289\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7817 - loss: 0.5579 - val_accuracy: 0.8589 - val_loss: 0.3461\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8763 - loss: 0.3718 - val_accuracy: 0.9141 - val_loss: 0.2344\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8757 - loss: 0.3795 - val_accuracy: 0.9264 - val_loss: 0.2024\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9110 - loss: 0.2694 - val_accuracy: 0.9632 - val_loss: 0.1518\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9153 - loss: 0.2469 - val_accuracy: 0.9387 - val_loss: 0.1440\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9067 - loss: 0.2313 - val_accuracy: 0.9325 - val_loss: 0.2232\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9004 - loss: 0.2574 - val_accuracy: 0.9571 - val_loss: 0.1184\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9131 - loss: 0.1971 - val_accuracy: 0.9509 - val_loss: 0.1292\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9629 - loss: 0.1330 - val_accuracy: 0.9693 - val_loss: 0.0950\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9544 - loss: 0.1202 - val_accuracy: 0.9632 - val_loss: 0.0896\n",
            "Epoch 25/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9620 - loss: 0.1060 - val_accuracy: 0.9693 - val_loss: 0.0749\n",
            "Epoch 26/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9647 - loss: 0.1021 - val_accuracy: 0.9509 - val_loss: 0.1217\n",
            "Epoch 27/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9439 - loss: 0.1288 - val_accuracy: 0.9816 - val_loss: 0.0713\n",
            "Epoch 28/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9871 - loss: 0.0668 - val_accuracy: 0.9755 - val_loss: 0.0678\n",
            "Epoch 29/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9786 - loss: 0.0821 - val_accuracy: 0.9755 - val_loss: 0.0637\n",
            "Epoch 30/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9788 - loss: 0.0738 - val_accuracy: 0.9325 - val_loss: 0.2197\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
            "Confusion Matrix:\n",
            "[[54  0  0]\n",
            " [ 0 49  3]\n",
            " [ 0  1 56]]\n",
            "Precision: 0.9764, Recall: 0.9749, Accuracy: 0.9755, F1 Score: 0.9754\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {2: 57, 0: 54, 1: 52}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.3650 - loss: 1.1007 - val_accuracy: 0.3436 - val_loss: 1.0971\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3169 - loss: 1.1081 - val_accuracy: 0.3681 - val_loss: 1.0967\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3285 - loss: 1.1057 - val_accuracy: 0.3681 - val_loss: 1.0954\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3549 - loss: 1.1026 - val_accuracy: 0.3742 - val_loss: 1.0944\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3408 - loss: 1.0996 - val_accuracy: 0.4110 - val_loss: 1.0927\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3516 - loss: 1.0978 - val_accuracy: 0.3988 - val_loss: 1.0898\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3503 - loss: 1.0965 - val_accuracy: 0.3988 - val_loss: 1.0855\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4233 - loss: 1.0918 - val_accuracy: 0.4540 - val_loss: 1.0757\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4241 - loss: 1.0835 - val_accuracy: 0.4294 - val_loss: 1.0647\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4505 - loss: 1.0641 - val_accuracy: 0.4785 - val_loss: 1.0359\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5100 - loss: 1.0321 - val_accuracy: 0.5706 - val_loss: 0.9981\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5164 - loss: 0.9825 - val_accuracy: 0.7975 - val_loss: 0.6574\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7163 - loss: 0.6932 - val_accuracy: 0.7730 - val_loss: 0.4923\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7966 - loss: 0.5259 - val_accuracy: 0.7607 - val_loss: 0.4982\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8176 - loss: 0.4619 - val_accuracy: 0.9141 - val_loss: 0.2674\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8707 - loss: 0.3265 - val_accuracy: 0.8957 - val_loss: 0.2789\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9084 - loss: 0.2542 - val_accuracy: 0.8344 - val_loss: 0.3451\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8664 - loss: 0.3453 - val_accuracy: 0.9325 - val_loss: 0.1975\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9439 - loss: 0.1854 - val_accuracy: 0.9755 - val_loss: 0.1166\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9390 - loss: 0.1697 - val_accuracy: 0.9202 - val_loss: 0.1835\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9283 - loss: 0.1911 - val_accuracy: 0.9632 - val_loss: 0.1135\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9691 - loss: 0.1282 - val_accuracy: 0.9632 - val_loss: 0.1182\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9617 - loss: 0.1141 - val_accuracy: 0.9755 - val_loss: 0.0640\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9456 - loss: 0.1211 - val_accuracy: 0.9264 - val_loss: 0.1623\n",
            "Epoch 25/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9663 - loss: 0.1398 - val_accuracy: 0.9755 - val_loss: 0.0839\n",
            "Epoch 26/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9688 - loss: 0.1139 - val_accuracy: 0.9509 - val_loss: 0.1281\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
            "Confusion Matrix:\n",
            "[[52  2  0]\n",
            " [ 0 51  1]\n",
            " [ 0  1 56]]\n",
            "Precision: 0.9756, Recall: 0.9754, Accuracy: 0.9755, F1 Score: 0.9753\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {2: 58, 0: 53, 1: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.3583 - loss: 1.0985 - val_accuracy: 0.3148 - val_loss: 1.1008\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2998 - loss: 1.1031 - val_accuracy: 0.3642 - val_loss: 1.0984\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3384 - loss: 1.1002 - val_accuracy: 0.3025 - val_loss: 1.0982\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3608 - loss: 1.0955 - val_accuracy: 0.3642 - val_loss: 1.0965\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3880 - loss: 1.0943 - val_accuracy: 0.3148 - val_loss: 1.0978\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3514 - loss: 1.0924 - val_accuracy: 0.3395 - val_loss: 1.0945\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3504 - loss: 1.0956 - val_accuracy: 0.4012 - val_loss: 1.0910\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3815 - loss: 1.0919 - val_accuracy: 0.4506 - val_loss: 1.0872\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4109 - loss: 1.0834 - val_accuracy: 0.4136 - val_loss: 1.0821\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4056 - loss: 1.0771 - val_accuracy: 0.2963 - val_loss: 1.0936\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4201 - loss: 1.0618 - val_accuracy: 0.3333 - val_loss: 1.1005\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4722 - loss: 1.0472 - val_accuracy: 0.3642 - val_loss: 1.0728\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4698 - loss: 1.0278 - val_accuracy: 0.4815 - val_loss: 1.0014\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6167 - loss: 0.9154 - val_accuracy: 0.6914 - val_loss: 0.7277\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6573 - loss: 0.7603 - val_accuracy: 0.6852 - val_loss: 0.6502\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7599 - loss: 0.6034 - val_accuracy: 0.8519 - val_loss: 0.4381\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8240 - loss: 0.4347 - val_accuracy: 0.9136 - val_loss: 0.3418\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8369 - loss: 0.3912 - val_accuracy: 0.8642 - val_loss: 0.3415\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8634 - loss: 0.3509 - val_accuracy: 0.9506 - val_loss: 0.2108\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9099 - loss: 0.2531 - val_accuracy: 0.9198 - val_loss: 0.2046\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8838 - loss: 0.2520 - val_accuracy: 0.9259 - val_loss: 0.2327\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8913 - loss: 0.2879 - val_accuracy: 0.9630 - val_loss: 0.1583\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9374 - loss: 0.2114 - val_accuracy: 0.9568 - val_loss: 0.1609\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9411 - loss: 0.1973 - val_accuracy: 0.9444 - val_loss: 0.1828\n",
            "Epoch 25/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9336 - loss: 0.1798 - val_accuracy: 0.9074 - val_loss: 0.1835\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "Confusion Matrix:\n",
            "[[51  2  0]\n",
            " [ 0 49  2]\n",
            " [ 0  2 56]]\n",
            "Precision: 0.9633, Recall: 0.9629, Accuracy: 0.9630, F1 Score: 0.9629\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {2: 58, 0: 53, 1: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.3084 - loss: 1.0993 - val_accuracy: 0.3642 - val_loss: 1.0973\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3519 - loss: 1.0971 - val_accuracy: 0.3333 - val_loss: 1.0982\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3359 - loss: 1.0981 - val_accuracy: 0.3148 - val_loss: 1.0984\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3199 - loss: 1.0973 - val_accuracy: 0.3580 - val_loss: 1.0973\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3586 - loss: 1.0974 - val_accuracy: 0.3148 - val_loss: 1.0966\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3284 - loss: 1.0960 - val_accuracy: 0.3395 - val_loss: 1.0949\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3312 - loss: 1.0972 - val_accuracy: 0.4321 - val_loss: 1.0914\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3905 - loss: 1.0907 - val_accuracy: 0.4691 - val_loss: 1.0861\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4304 - loss: 1.0841 - val_accuracy: 0.4444 - val_loss: 1.0644\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4165 - loss: 1.0661 - val_accuracy: 0.5123 - val_loss: 1.0372\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4714 - loss: 1.0579 - val_accuracy: 0.5494 - val_loss: 1.0055\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4952 - loss: 1.0303 - val_accuracy: 0.6173 - val_loss: 0.9457\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5742 - loss: 0.9396 - val_accuracy: 0.6790 - val_loss: 0.7356\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6655 - loss: 0.7763 - val_accuracy: 0.7593 - val_loss: 0.5413\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7735 - loss: 0.5790 - val_accuracy: 0.8580 - val_loss: 0.3896\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8410 - loss: 0.4410 - val_accuracy: 0.7531 - val_loss: 0.4563\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8203 - loss: 0.4525 - val_accuracy: 0.8889 - val_loss: 0.3161\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8837 - loss: 0.3635 - val_accuracy: 0.9074 - val_loss: 0.2539\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8920 - loss: 0.2887 - val_accuracy: 0.9383 - val_loss: 0.1691\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9353 - loss: 0.2237 - val_accuracy: 0.9383 - val_loss: 0.1542\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9261 - loss: 0.2140 - val_accuracy: 0.8889 - val_loss: 0.2473\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9330 - loss: 0.1931 - val_accuracy: 0.9074 - val_loss: 0.1717\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9561 - loss: 0.1473 - val_accuracy: 0.9198 - val_loss: 0.2009\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "Confusion Matrix:\n",
            "[[52  1  0]\n",
            " [ 0 50  1]\n",
            " [ 0  8 50]]\n",
            "Precision: 0.9426, Recall: 0.9412, Accuracy: 0.9383, F1 Score: 0.9390\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {2: 58, 0: 53, 1: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.3403 - loss: 1.1007 - val_accuracy: 0.3148 - val_loss: 1.0995\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3604 - loss: 1.1002 - val_accuracy: 0.3704 - val_loss: 1.0972\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3366 - loss: 1.1026 - val_accuracy: 0.3580 - val_loss: 1.0971\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3419 - loss: 1.1005 - val_accuracy: 0.3889 - val_loss: 1.0950\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3528 - loss: 1.0999 - val_accuracy: 0.3704 - val_loss: 1.0933\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3215 - loss: 1.1005 - val_accuracy: 0.4136 - val_loss: 1.0901\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3847 - loss: 1.0985 - val_accuracy: 0.4136 - val_loss: 1.0875\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3688 - loss: 1.0966 - val_accuracy: 0.4136 - val_loss: 1.0806\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3806 - loss: 1.0961 - val_accuracy: 0.3704 - val_loss: 1.0744\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3555 - loss: 1.0920 - val_accuracy: 0.3827 - val_loss: 1.0648\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3756 - loss: 1.0952 - val_accuracy: 0.3951 - val_loss: 1.0556\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3992 - loss: 1.0867 - val_accuracy: 0.4444 - val_loss: 1.0276\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4531 - loss: 1.0492 - val_accuracy: 0.4815 - val_loss: 0.9599\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5470 - loss: 0.9884 - val_accuracy: 0.6790 - val_loss: 0.7433\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7071 - loss: 0.7208 - val_accuracy: 0.8642 - val_loss: 0.4014\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 0.5647 - val_accuracy: 0.9136 - val_loss: 0.3036\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8468 - loss: 0.3944 - val_accuracy: 0.9383 - val_loss: 0.2097\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8702 - loss: 0.3424 - val_accuracy: 0.9383 - val_loss: 0.2420\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8883 - loss: 0.3275 - val_accuracy: 0.9198 - val_loss: 0.1951\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9127 - loss: 0.2591 - val_accuracy: 0.9753 - val_loss: 0.1034\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9292 - loss: 0.1835 - val_accuracy: 0.9630 - val_loss: 0.0945\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9587 - loss: 0.1437 - val_accuracy: 0.9630 - val_loss: 0.1067\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9436 - loss: 0.1412 - val_accuracy: 0.9444 - val_loss: 0.1569\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9307 - loss: 0.1949 - val_accuracy: 0.9506 - val_loss: 0.1031\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "Confusion Matrix:\n",
            "[[53  0  0]\n",
            " [ 1 45  5]\n",
            " [ 0  0 58]]\n",
            "Precision: 0.9674, Recall: 0.9608, Accuracy: 0.9630, F1 Score: 0.9623\n",
            "\n",
            "=== 5-Fold Cross-Validation Summary ===\n",
            "Avg Precision: 0.9651\n",
            "Avg Recall:    0.9630\n",
            "Avg Accuracy:  0.9630\n",
            "Avg F1 Score:  0.9630\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.3427 - loss: 1.0995 - val_accuracy: 0.3719 - val_loss: 1.0946\n",
            "Epoch 2/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3737 - loss: 1.0940 - val_accuracy: 0.4064 - val_loss: 1.0871\n",
            "Epoch 3/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4163 - loss: 1.0805 - val_accuracy: 0.4655 - val_loss: 1.0512\n",
            "Epoch 4/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4941 - loss: 1.0141 - val_accuracy: 0.6650 - val_loss: 0.6993\n",
            "Epoch 5/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7770 - loss: 0.5517 - val_accuracy: 0.8941 - val_loss: 0.2492\n",
            "Epoch 6/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9005 - loss: 0.2777 - val_accuracy: 0.9680 - val_loss: 0.0868\n",
            "Epoch 7/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9528 - loss: 0.1448 - val_accuracy: 0.9852 - val_loss: 0.0436\n",
            "Epoch 8/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9765 - loss: 0.0770 - val_accuracy: 0.9852 - val_loss: 0.0642\n",
            "Epoch 9/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0702 - val_accuracy: 0.9803 - val_loss: 0.0706\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "[[53  0  0]\n",
            " [ 1 50  0]\n",
            " [ 0  0 58]]\n",
            "Test Accuracy:  0.9938\n",
            "Test Precision: 0.9938\n",
            "Test Recall:    0.9935\n",
            "Test F1 Score:  0.9936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import joblib\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load and return features and labels\n",
        "def import_data():\n",
        "    data = pd.read_csv('mergedshuffledPlankV2keypoints.csv')\n",
        "    x = data.iloc[:, :-1].values\n",
        "    y = data['correct'].astype(int).values\n",
        "    y = np.searchsorted(np.unique(y), y)  # Make sure y is 0-based index\n",
        "    return x, y\n",
        "\n",
        "# Define the CNN-LSTM model\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main script\n",
        "x, y = import_data()\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Create 6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "# Variables to track the best model\n",
        "best_f1_score = -float('inf')\n",
        "best_model = None\n",
        "best_scaler = None\n",
        "best_fold = 0\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train_raw, x_val_raw = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Fit scaler only on training data\n",
        "    scaler = MinMaxScaler()\n",
        "    x_train = scaler.fit_transform(x_train_raw)\n",
        "    x_val = scaler.transform(x_val_raw)\n",
        "\n",
        "    # Reshape for CNN input\n",
        "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    # Class weights for imbalance\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Train model\n",
        "    model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "              validation_data=(x_val, y_val),\n",
        "              class_weight=class_weights,\n",
        "              callbacks=[early_stop],\n",
        "              verbose=1)\n",
        "\n",
        "    # Evaluate\n",
        "    preds = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, preds, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, preds))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    # Save the best model based on F1 score\n",
        "    if f1 > best_f1_score:\n",
        "        best_f1_score = f1\n",
        "        best_model = model\n",
        "        best_scaler = scaler\n",
        "        best_fold = fold_index\n",
        "        # Save the best model and scaler\n",
        "        model.save('best_model.keras')\n",
        "        joblib.dump(scaler, 'best_scaler.pkl')\n",
        "        print(f\"Saved best model and scaler from Fold {fold_index} with F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Report average scores\n",
        "print(\"\\n=== 5-Fold Cross-Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "\n",
        "# === Final Testing on Fold 6 ===\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "test_index = test_fold[1]\n",
        "x_train_raw, x_test_raw = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Refit scaler only on training data\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train_raw)\n",
        "x_test = scaler.transform(x_test_raw)\n",
        "\n",
        "# Reshape for CNN input\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train final model (Fold 6) with stricter early stopping\n",
        "final_model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "final_model.fit(x_train, y_train, epochs=30, batch_size=32,\n",
        "                validation_split=0.1, class_weight=class_weights,\n",
        "                callbacks=[early_stop], verbose=1)\n",
        "\n",
        "# Final test evaluation\n",
        "test_preds = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_preds)\n",
        "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
        "test_precision = precision_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")\n",
        "\n",
        "print(f\"\\n=== Best Model Summary ===\")\n",
        "print(f\"Best model is from Fold {best_fold} with F1 Score: {best_f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzEQsnior6p3",
        "outputId": "f564764e-7b75-40bf-dacd-8cfb328fafa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {2: 57, 0: 54, 1: 52}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.3609 - loss: 1.0984 - val_accuracy: 0.3742 - val_loss: 1.0979\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3435 - loss: 1.0960 - val_accuracy: 0.3190 - val_loss: 1.0986\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3643 - loss: 1.0969 - val_accuracy: 0.3436 - val_loss: 1.0975\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3426 - loss: 1.0978 - val_accuracy: 0.3252 - val_loss: 1.0979\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3727 - loss: 1.0982 - val_accuracy: 0.3865 - val_loss: 1.0945\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3944 - loss: 1.0895 - val_accuracy: 0.4233 - val_loss: 1.0914\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3804 - loss: 1.0881 - val_accuracy: 0.3620 - val_loss: 1.0849\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4261 - loss: 1.0780 - val_accuracy: 0.4601 - val_loss: 1.0747\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4386 - loss: 1.0644 - val_accuracy: 0.4785 - val_loss: 1.0562\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4344 - loss: 1.0497 - val_accuracy: 0.4847 - val_loss: 1.0248\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4978 - loss: 1.0234 - val_accuracy: 0.6135 - val_loss: 0.9662\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5955 - loss: 0.9414 - val_accuracy: 0.6871 - val_loss: 0.8070\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6407 - loss: 0.8188 - val_accuracy: 0.7485 - val_loss: 0.6304\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6981 - loss: 0.6806 - val_accuracy: 0.7178 - val_loss: 0.6289\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7817 - loss: 0.5579 - val_accuracy: 0.8589 - val_loss: 0.3461\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8763 - loss: 0.3718 - val_accuracy: 0.9141 - val_loss: 0.2344\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8757 - loss: 0.3795 - val_accuracy: 0.9264 - val_loss: 0.2024\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9110 - loss: 0.2694 - val_accuracy: 0.9632 - val_loss: 0.1518\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9153 - loss: 0.2469 - val_accuracy: 0.9387 - val_loss: 0.1440\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9067 - loss: 0.2313 - val_accuracy: 0.9325 - val_loss: 0.2232\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9004 - loss: 0.2574 - val_accuracy: 0.9571 - val_loss: 0.1184\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9131 - loss: 0.1971 - val_accuracy: 0.9509 - val_loss: 0.1292\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9629 - loss: 0.1330 - val_accuracy: 0.9693 - val_loss: 0.0950\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9544 - loss: 0.1202 - val_accuracy: 0.9632 - val_loss: 0.0896\n",
            "Epoch 25/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1060 - val_accuracy: 0.9693 - val_loss: 0.0749\n",
            "Epoch 26/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9647 - loss: 0.1021 - val_accuracy: 0.9509 - val_loss: 0.1217\n",
            "Epoch 27/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9439 - loss: 0.1288 - val_accuracy: 0.9816 - val_loss: 0.0713\n",
            "Epoch 28/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.0668 - val_accuracy: 0.9755 - val_loss: 0.0678\n",
            "Epoch 29/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9786 - loss: 0.0821 - val_accuracy: 0.9755 - val_loss: 0.0637\n",
            "Epoch 30/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0738 - val_accuracy: 0.9325 - val_loss: 0.2197\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Confusion Matrix:\n",
            "[[54  0  0]\n",
            " [ 0 49  3]\n",
            " [ 0  1 56]]\n",
            "Precision: 0.9764, Recall: 0.9749, Accuracy: 0.9755, F1 Score: 0.9754\n",
            "Saved best model and scaler from Fold 1 with F1 Score: 0.9754\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {2: 57, 0: 54, 1: 52}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.3650 - loss: 1.1007 - val_accuracy: 0.3436 - val_loss: 1.0971\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3169 - loss: 1.1081 - val_accuracy: 0.3681 - val_loss: 1.0967\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3285 - loss: 1.1057 - val_accuracy: 0.3681 - val_loss: 1.0954\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3549 - loss: 1.1026 - val_accuracy: 0.3742 - val_loss: 1.0944\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3408 - loss: 1.0996 - val_accuracy: 0.4110 - val_loss: 1.0927\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3516 - loss: 1.0978 - val_accuracy: 0.3988 - val_loss: 1.0898\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3503 - loss: 1.0965 - val_accuracy: 0.3988 - val_loss: 1.0855\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4233 - loss: 1.0918 - val_accuracy: 0.4540 - val_loss: 1.0757\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4241 - loss: 1.0835 - val_accuracy: 0.4294 - val_loss: 1.0647\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4505 - loss: 1.0641 - val_accuracy: 0.4785 - val_loss: 1.0359\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5100 - loss: 1.0321 - val_accuracy: 0.5706 - val_loss: 0.9981\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5164 - loss: 0.9825 - val_accuracy: 0.7975 - val_loss: 0.6574\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7163 - loss: 0.6932 - val_accuracy: 0.7730 - val_loss: 0.4923\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7966 - loss: 0.5259 - val_accuracy: 0.7607 - val_loss: 0.4982\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8176 - loss: 0.4619 - val_accuracy: 0.9141 - val_loss: 0.2674\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8707 - loss: 0.3265 - val_accuracy: 0.8957 - val_loss: 0.2789\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9084 - loss: 0.2542 - val_accuracy: 0.8344 - val_loss: 0.3451\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8664 - loss: 0.3453 - val_accuracy: 0.9325 - val_loss: 0.1975\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9439 - loss: 0.1854 - val_accuracy: 0.9755 - val_loss: 0.1166\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.1697 - val_accuracy: 0.9202 - val_loss: 0.1835\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9283 - loss: 0.1911 - val_accuracy: 0.9632 - val_loss: 0.1135\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9691 - loss: 0.1282 - val_accuracy: 0.9632 - val_loss: 0.1182\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.1141 - val_accuracy: 0.9755 - val_loss: 0.0640\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.1211 - val_accuracy: 0.9264 - val_loss: 0.1623\n",
            "Epoch 25/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9663 - loss: 0.1398 - val_accuracy: 0.9755 - val_loss: 0.0839\n",
            "Epoch 26/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9688 - loss: 0.1139 - val_accuracy: 0.9509 - val_loss: 0.1281\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Confusion Matrix:\n",
            "[[52  2  0]\n",
            " [ 0 51  1]\n",
            " [ 0  1 56]]\n",
            "Precision: 0.9756, Recall: 0.9754, Accuracy: 0.9755, F1 Score: 0.9753\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {2: 58, 0: 53, 1: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.3583 - loss: 1.0985 - val_accuracy: 0.3148 - val_loss: 1.1008\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2998 - loss: 1.1031 - val_accuracy: 0.3642 - val_loss: 1.0984\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3384 - loss: 1.1002 - val_accuracy: 0.3025 - val_loss: 1.0982\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3608 - loss: 1.0955 - val_accuracy: 0.3642 - val_loss: 1.0965\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3880 - loss: 1.0943 - val_accuracy: 0.3148 - val_loss: 1.0978\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3514 - loss: 1.0924 - val_accuracy: 0.3395 - val_loss: 1.0945\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3504 - loss: 1.0956 - val_accuracy: 0.4012 - val_loss: 1.0910\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3815 - loss: 1.0919 - val_accuracy: 0.4506 - val_loss: 1.0872\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4109 - loss: 1.0834 - val_accuracy: 0.4136 - val_loss: 1.0821\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4056 - loss: 1.0771 - val_accuracy: 0.2963 - val_loss: 1.0936\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4201 - loss: 1.0618 - val_accuracy: 0.3333 - val_loss: 1.1005\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4722 - loss: 1.0472 - val_accuracy: 0.3642 - val_loss: 1.0728\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4698 - loss: 1.0278 - val_accuracy: 0.4815 - val_loss: 1.0014\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6167 - loss: 0.9154 - val_accuracy: 0.6914 - val_loss: 0.7277\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6573 - loss: 0.7603 - val_accuracy: 0.6852 - val_loss: 0.6502\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7599 - loss: 0.6034 - val_accuracy: 0.8519 - val_loss: 0.4381\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8240 - loss: 0.4347 - val_accuracy: 0.9136 - val_loss: 0.3418\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8369 - loss: 0.3912 - val_accuracy: 0.8642 - val_loss: 0.3415\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8634 - loss: 0.3509 - val_accuracy: 0.9506 - val_loss: 0.2108\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9099 - loss: 0.2531 - val_accuracy: 0.9198 - val_loss: 0.2046\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8838 - loss: 0.2520 - val_accuracy: 0.9259 - val_loss: 0.2327\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8913 - loss: 0.2879 - val_accuracy: 0.9630 - val_loss: 0.1583\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9374 - loss: 0.2114 - val_accuracy: 0.9568 - val_loss: 0.1609\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9411 - loss: 0.1973 - val_accuracy: 0.9444 - val_loss: 0.1828\n",
            "Epoch 25/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.1798 - val_accuracy: 0.9074 - val_loss: 0.1835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c693c3e7420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Confusion Matrix:\n",
            "[[51  2  0]\n",
            " [ 0 49  2]\n",
            " [ 0  2 56]]\n",
            "Precision: 0.9633, Recall: 0.9629, Accuracy: 0.9630, F1 Score: 0.9629\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {2: 58, 0: 53, 1: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.3084 - loss: 1.0993 - val_accuracy: 0.3642 - val_loss: 1.0973\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3519 - loss: 1.0971 - val_accuracy: 0.3333 - val_loss: 1.0982\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3359 - loss: 1.0981 - val_accuracy: 0.3148 - val_loss: 1.0984\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3199 - loss: 1.0973 - val_accuracy: 0.3580 - val_loss: 1.0973\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3586 - loss: 1.0974 - val_accuracy: 0.3148 - val_loss: 1.0966\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3284 - loss: 1.0960 - val_accuracy: 0.3395 - val_loss: 1.0949\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3312 - loss: 1.0972 - val_accuracy: 0.4321 - val_loss: 1.0914\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3905 - loss: 1.0907 - val_accuracy: 0.4691 - val_loss: 1.0861\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4304 - loss: 1.0841 - val_accuracy: 0.4444 - val_loss: 1.0644\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4165 - loss: 1.0661 - val_accuracy: 0.5123 - val_loss: 1.0372\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4714 - loss: 1.0579 - val_accuracy: 0.5494 - val_loss: 1.0055\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4952 - loss: 1.0303 - val_accuracy: 0.6173 - val_loss: 0.9457\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5742 - loss: 0.9396 - val_accuracy: 0.6790 - val_loss: 0.7356\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6655 - loss: 0.7763 - val_accuracy: 0.7593 - val_loss: 0.5413\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7735 - loss: 0.5790 - val_accuracy: 0.8580 - val_loss: 0.3896\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8410 - loss: 0.4410 - val_accuracy: 0.7531 - val_loss: 0.4563\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8203 - loss: 0.4525 - val_accuracy: 0.8889 - val_loss: 0.3161\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8837 - loss: 0.3635 - val_accuracy: 0.9074 - val_loss: 0.2539\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.2887 - val_accuracy: 0.9383 - val_loss: 0.1691\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9353 - loss: 0.2237 - val_accuracy: 0.9383 - val_loss: 0.1542\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9261 - loss: 0.2140 - val_accuracy: 0.8889 - val_loss: 0.2473\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9330 - loss: 0.1931 - val_accuracy: 0.9074 - val_loss: 0.1717\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9561 - loss: 0.1473 - val_accuracy: 0.9198 - val_loss: 0.2009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c693c18eb60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Confusion Matrix:\n",
            "[[52  1  0]\n",
            " [ 0 50  1]\n",
            " [ 0  8 50]]\n",
            "Precision: 0.9426, Recall: 0.9412, Accuracy: 0.9383, F1 Score: 0.9390\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {2: 58, 0: 53, 1: 51}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.3403 - loss: 1.1007 - val_accuracy: 0.3148 - val_loss: 1.0995\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3604 - loss: 1.1002 - val_accuracy: 0.3704 - val_loss: 1.0972\n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3366 - loss: 1.1026 - val_accuracy: 0.3580 - val_loss: 1.0971\n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3419 - loss: 1.1005 - val_accuracy: 0.3889 - val_loss: 1.0950\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3528 - loss: 1.0999 - val_accuracy: 0.3704 - val_loss: 1.0933\n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3215 - loss: 1.1005 - val_accuracy: 0.4136 - val_loss: 1.0901\n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3847 - loss: 1.0985 - val_accuracy: 0.4136 - val_loss: 1.0875\n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3688 - loss: 1.0966 - val_accuracy: 0.4136 - val_loss: 1.0806\n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3806 - loss: 1.0961 - val_accuracy: 0.3704 - val_loss: 1.0744\n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3555 - loss: 1.0920 - val_accuracy: 0.3827 - val_loss: 1.0648\n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3756 - loss: 1.0952 - val_accuracy: 0.3951 - val_loss: 1.0556\n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3992 - loss: 1.0867 - val_accuracy: 0.4444 - val_loss: 1.0276\n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4531 - loss: 1.0492 - val_accuracy: 0.4815 - val_loss: 0.9599\n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5470 - loss: 0.9884 - val_accuracy: 0.6790 - val_loss: 0.7433\n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7071 - loss: 0.7208 - val_accuracy: 0.8642 - val_loss: 0.4014\n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7784 - loss: 0.5647 - val_accuracy: 0.9136 - val_loss: 0.3036\n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8468 - loss: 0.3944 - val_accuracy: 0.9383 - val_loss: 0.2097\n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8702 - loss: 0.3424 - val_accuracy: 0.9383 - val_loss: 0.2420\n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8883 - loss: 0.3275 - val_accuracy: 0.9198 - val_loss: 0.1951\n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9127 - loss: 0.2591 - val_accuracy: 0.9753 - val_loss: 0.1034\n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9292 - loss: 0.1835 - val_accuracy: 0.9630 - val_loss: 0.0945\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1437 - val_accuracy: 0.9630 - val_loss: 0.1067\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9436 - loss: 0.1412 - val_accuracy: 0.9444 - val_loss: 0.1569\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9307 - loss: 0.1949 - val_accuracy: 0.9506 - val_loss: 0.1031\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Confusion Matrix:\n",
            "[[53  0  0]\n",
            " [ 1 45  5]\n",
            " [ 0  0 58]]\n",
            "Precision: 0.9674, Recall: 0.9608, Accuracy: 0.9630, F1 Score: 0.9623\n",
            "\n",
            "=== 5-Fold Cross-Validation Summary ===\n",
            "Avg Precision: 0.9651\n",
            "Avg Recall:    0.9630\n",
            "Avg Accuracy:  0.9630\n",
            "Avg F1 Score:  0.9630\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3427 - loss: 1.0995 - val_accuracy: 0.3719 - val_loss: 1.0946\n",
            "Epoch 2/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3737 - loss: 1.0940 - val_accuracy: 0.4064 - val_loss: 1.0871\n",
            "Epoch 3/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4163 - loss: 1.0805 - val_accuracy: 0.4655 - val_loss: 1.0512\n",
            "Epoch 4/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4941 - loss: 1.0141 - val_accuracy: 0.6650 - val_loss: 0.6993\n",
            "Epoch 5/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7770 - loss: 0.5517 - val_accuracy: 0.8941 - val_loss: 0.2492\n",
            "Epoch 6/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9005 - loss: 0.2777 - val_accuracy: 0.9680 - val_loss: 0.0868\n",
            "Epoch 7/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9528 - loss: 0.1448 - val_accuracy: 0.9852 - val_loss: 0.0436\n",
            "Epoch 8/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9765 - loss: 0.0770 - val_accuracy: 0.9852 - val_loss: 0.0642\n",
            "Epoch 9/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0702 - val_accuracy: 0.9803 - val_loss: 0.0706\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "[[53  0  0]\n",
            " [ 1 50  0]\n",
            " [ 0  0 58]]\n",
            "Test Accuracy:  0.9938\n",
            "Test Precision: 0.9938\n",
            "Test Recall:    0.9935\n",
            "Test F1 Score:  0.9936\n",
            "Saved best model and scaler from Fold 6 with F1 Score: 0.9936\n",
            "\n",
            "=== Best Model Summary ===\n",
            "Best model is from Fold 6 with F1 Score: 0.9936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSYrDHl_Zdd7"
      },
      "source": [
        "## (3) CNN-LSTM augmentation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCy1ZETYZhtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16465277-9c86-4dc1-d5bf-2416b48e3a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced class distribution:\n",
            "1    346\n",
            "2    346\n",
            "0    346\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Fold 1 ===\n",
            "Class distribution: {1: 58, 2: 58, 0: 57}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 77ms/step - accuracy: 0.3456 - loss: 1.0981 - val_accuracy: 0.3931 - val_loss: 1.0960\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3325 - loss: 1.0990 - val_accuracy: 0.3353 - val_loss: 1.0945\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3364 - loss: 1.0985 - val_accuracy: 0.3353 - val_loss: 1.0915\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3585 - loss: 1.0968 - val_accuracy: 0.4104 - val_loss: 1.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3956 - loss: 1.0844 - val_accuracy: 0.3815 - val_loss: 1.0764\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4046 - loss: 1.0873 - val_accuracy: 0.4740 - val_loss: 1.0533\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4085 - loss: 1.0506 - val_accuracy: 0.4798 - val_loss: 1.0268\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4894 - loss: 1.0179 - val_accuracy: 0.6705 - val_loss: 0.8154\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6161 - loss: 0.8547 - val_accuracy: 0.8150 - val_loss: 0.6095\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7194 - loss: 0.6609 - val_accuracy: 0.9306 - val_loss: 0.3115\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4855 - val_accuracy: 0.9249 - val_loss: 0.2881\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8357 - loss: 0.4123 - val_accuracy: 0.8497 - val_loss: 0.3350\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8324 - loss: 0.4155 - val_accuracy: 0.9538 - val_loss: 0.1967\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8766 - loss: 0.3345 - val_accuracy: 0.9480 - val_loss: 0.1732\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8713 - loss: 0.3074 - val_accuracy: 0.9480 - val_loss: 0.1681\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8998 - loss: 0.2762 - val_accuracy: 0.9422 - val_loss: 0.1551\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8922 - loss: 0.2861 - val_accuracy: 0.9538 - val_loss: 0.1427\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8857 - loss: 0.2708 - val_accuracy: 0.9595 - val_loss: 0.1097\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9039 - loss: 0.2333 - val_accuracy: 0.9711 - val_loss: 0.1071\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9079 - loss: 0.2230 - val_accuracy: 0.9653 - val_loss: 0.0822\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9102 - loss: 0.2121 - val_accuracy: 0.9884 - val_loss: 0.0956\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9201 - loss: 0.1921 - val_accuracy: 0.9827 - val_loss: 0.0704\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9330 - loss: 0.1843 - val_accuracy: 0.9595 - val_loss: 0.1076\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9225 - loss: 0.2111 - val_accuracy: 0.9538 - val_loss: 0.0861\n",
            "Epoch 25/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9332 - loss: 0.1771 - val_accuracy: 0.9827 - val_loss: 0.0755\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Confusion Matrix:\n",
            "[[56  1  0]\n",
            " [ 1 57  0]\n",
            " [ 0  1 57]]\n",
            "Precision: 0.9829, Recall: 0.9827, Accuracy: 0.9827, F1 Score: 0.9827\n",
            "\n",
            "=== Fold 2 ===\n",
            "Class distribution: {1: 58, 2: 58, 0: 57}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.3397 - loss: 1.1003 - val_accuracy: 0.3353 - val_loss: 1.0985\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3239 - loss: 1.1022 - val_accuracy: 0.3584 - val_loss: 1.0975\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3598 - loss: 1.0975 - val_accuracy: 0.3353 - val_loss: 1.0980\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3567 - loss: 1.0973 - val_accuracy: 0.3353 - val_loss: 1.0967\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3339 - loss: 1.0964 - val_accuracy: 0.3353 - val_loss: 1.0952\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3632 - loss: 1.0937 - val_accuracy: 0.3873 - val_loss: 1.0835\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3796 - loss: 1.0883 - val_accuracy: 0.4740 - val_loss: 1.0715\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4209 - loss: 1.0771 - val_accuracy: 0.4682 - val_loss: 1.0591\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4529 - loss: 1.0355 - val_accuracy: 0.4451 - val_loss: 1.0359\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5181 - loss: 0.9303 - val_accuracy: 0.7977 - val_loss: 0.7335\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6072 - loss: 0.8210 - val_accuracy: 0.6301 - val_loss: 0.7751\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6773 - loss: 0.7410 - val_accuracy: 0.8035 - val_loss: 0.5614\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7317 - loss: 0.6194 - val_accuracy: 0.7803 - val_loss: 0.5315\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7180 - loss: 0.6307 - val_accuracy: 0.8728 - val_loss: 0.3847\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7622 - loss: 0.5249 - val_accuracy: 0.7919 - val_loss: 0.4513\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7369 - loss: 0.5729 - val_accuracy: 0.8786 - val_loss: 0.3478\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8057 - loss: 0.4821 - val_accuracy: 0.8497 - val_loss: 0.3740\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8086 - loss: 0.4936 - val_accuracy: 0.8728 - val_loss: 0.2844\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8024 - loss: 0.4605 - val_accuracy: 0.9191 - val_loss: 0.2652\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8068 - loss: 0.4331 - val_accuracy: 0.9595 - val_loss: 0.2272\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8544 - loss: 0.3813 - val_accuracy: 0.9827 - val_loss: 0.1657\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8435 - loss: 0.3735 - val_accuracy: 0.9480 - val_loss: 0.1828\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8430 - loss: 0.3887 - val_accuracy: 0.9942 - val_loss: 0.1245\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8957 - loss: 0.3007 - val_accuracy: 0.8902 - val_loss: 0.2264\n",
            "Epoch 25/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8458 - loss: 0.3788 - val_accuracy: 0.9653 - val_loss: 0.1487\n",
            "Epoch 26/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8669 - loss: 0.3020 - val_accuracy: 0.9884 - val_loss: 0.1106\n",
            "Epoch 27/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8705 - loss: 0.3205 - val_accuracy: 0.9827 - val_loss: 0.1112\n",
            "Epoch 28/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8833 - loss: 0.2988 - val_accuracy: 0.9769 - val_loss: 0.1032\n",
            "Epoch 29/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9108 - loss: 0.2545 - val_accuracy: 0.9595 - val_loss: 0.0954\n",
            "Epoch 30/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8943 - loss: 0.2551 - val_accuracy: 0.9595 - val_loss: 0.1035\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Confusion Matrix:\n",
            "[[57  0  0]\n",
            " [ 2 56  0]\n",
            " [ 0  5 53]]\n",
            "Precision: 0.9614, Recall: 0.9598, Accuracy: 0.9595, F1 Score: 0.9596\n",
            "\n",
            "=== Fold 3 ===\n",
            "Class distribution: {1: 58, 0: 58, 2: 57}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.3618 - loss: 1.1005 - val_accuracy: 0.3353 - val_loss: 1.0986\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3275 - loss: 1.1033 - val_accuracy: 0.3353 - val_loss: 1.0979\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3240 - loss: 1.1029 - val_accuracy: 0.3353 - val_loss: 1.0974\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3216 - loss: 1.0998 - val_accuracy: 0.3353 - val_loss: 1.0969\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3228 - loss: 1.1014 - val_accuracy: 0.3584 - val_loss: 1.0965\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3357 - loss: 1.0985 - val_accuracy: 0.3353 - val_loss: 1.0965\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3242 - loss: 1.0987 - val_accuracy: 0.3353 - val_loss: 1.0946\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3236 - loss: 1.0970 - val_accuracy: 0.3410 - val_loss: 1.0932\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3458 - loss: 1.0966 - val_accuracy: 0.3410 - val_loss: 1.0911\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3589 - loss: 1.0958 - val_accuracy: 0.3468 - val_loss: 1.0938\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3623 - loss: 1.0885 - val_accuracy: 0.3931 - val_loss: 1.0742\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3916 - loss: 1.0727 - val_accuracy: 0.4682 - val_loss: 1.0591\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4693 - loss: 1.0510 - val_accuracy: 0.4855 - val_loss: 1.0404\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4782 - loss: 1.0194 - val_accuracy: 0.5607 - val_loss: 0.9287\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5263 - loss: 0.9304 - val_accuracy: 0.5896 - val_loss: 0.8130\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5712 - loss: 0.8333 - val_accuracy: 0.8092 - val_loss: 0.6629\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6799 - loss: 0.7213 - val_accuracy: 0.7399 - val_loss: 0.5692\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7337 - loss: 0.6272 - val_accuracy: 0.8266 - val_loss: 0.4237\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7676 - loss: 0.5397 - val_accuracy: 0.8613 - val_loss: 0.3862\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.4364 - val_accuracy: 0.9422 - val_loss: 0.2797\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8798 - loss: 0.3367 - val_accuracy: 0.9480 - val_loss: 0.1931\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8973 - loss: 0.2792 - val_accuracy: 0.9364 - val_loss: 0.1839\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8981 - loss: 0.2486 - val_accuracy: 0.9017 - val_loss: 0.2389\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9090 - loss: 0.2455 - val_accuracy: 0.8728 - val_loss: 0.2419\n",
            "Epoch 25/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9085 - loss: 0.2345 - val_accuracy: 0.9075 - val_loss: 0.1889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d3dfd2da660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
            "Confusion Matrix:\n",
            "[[56  2  0]\n",
            " [ 0 51  7]\n",
            " [ 0  2 55]]\n",
            "Precision: 0.9381, Recall: 0.9366, Accuracy: 0.9364, F1 Score: 0.9365\n",
            "\n",
            "=== Fold 4 ===\n",
            "Class distribution: {1: 58, 0: 58, 2: 57}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.3650 - loss: 1.1000 - val_accuracy: 0.3468 - val_loss: 1.0966\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3551 - loss: 1.0971 - val_accuracy: 0.3353 - val_loss: 1.0947\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3314 - loss: 1.0952 - val_accuracy: 0.3584 - val_loss: 1.0914\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3662 - loss: 1.0885 - val_accuracy: 0.3642 - val_loss: 1.0942\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3642 - loss: 1.0882 - val_accuracy: 0.4509 - val_loss: 1.0726\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4132 - loss: 1.0612 - val_accuracy: 0.3757 - val_loss: 1.0479\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4558 - loss: 1.0156 - val_accuracy: 0.5780 - val_loss: 0.9095\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5515 - loss: 0.8992 - val_accuracy: 0.7341 - val_loss: 0.6118\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6776 - loss: 0.6999 - val_accuracy: 0.8497 - val_loss: 0.4283\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7584 - loss: 0.5803 - val_accuracy: 0.8844 - val_loss: 0.3960\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8200 - loss: 0.4768 - val_accuracy: 0.9191 - val_loss: 0.2900\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8356 - loss: 0.4310 - val_accuracy: 0.9191 - val_loss: 0.2877\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8482 - loss: 0.3729 - val_accuracy: 0.9422 - val_loss: 0.2041\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8655 - loss: 0.3499 - val_accuracy: 0.9075 - val_loss: 0.2311\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8735 - loss: 0.3188 - val_accuracy: 0.9480 - val_loss: 0.1979\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8753 - loss: 0.2985 - val_accuracy: 0.9249 - val_loss: 0.1642\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8967 - loss: 0.2856 - val_accuracy: 0.9364 - val_loss: 0.1633\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9111 - loss: 0.2482 - val_accuracy: 0.9306 - val_loss: 0.1435\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8921 - loss: 0.2838 - val_accuracy: 0.8439 - val_loss: 0.3087\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8920 - loss: 0.2910 - val_accuracy: 0.9249 - val_loss: 0.1750\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9132 - loss: 0.2328 - val_accuracy: 0.9480 - val_loss: 0.1377\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9218 - loss: 0.2563 - val_accuracy: 0.8902 - val_loss: 0.2493\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9057 - loss: 0.2774 - val_accuracy: 0.9364 - val_loss: 0.1442\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9087 - loss: 0.2396 - val_accuracy: 0.9653 - val_loss: 0.1480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d3dfe2e91c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Confusion Matrix:\n",
            "[[55  3  0]\n",
            " [ 0 53  5]\n",
            " [ 0  1 56]]\n",
            "Precision: 0.9493, Recall: 0.9482, Accuracy: 0.9480, F1 Score: 0.9481\n",
            "\n",
            "=== Fold 5 ===\n",
            "Class distribution: {2: 58, 0: 58, 1: 57}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.3096 - loss: 1.1005 - val_accuracy: 0.3295 - val_loss: 1.0989\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3132 - loss: 1.1002 - val_accuracy: 0.3295 - val_loss: 1.0985\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3255 - loss: 1.1014 - val_accuracy: 0.3353 - val_loss: 1.0955\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3345 - loss: 1.0988 - val_accuracy: 0.3295 - val_loss: 1.0951\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3104 - loss: 1.1009 - val_accuracy: 0.3873 - val_loss: 1.0861\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3677 - loss: 1.0905 - val_accuracy: 0.3873 - val_loss: 1.0711\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3907 - loss: 1.0872 - val_accuracy: 0.3815 - val_loss: 1.0862\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3621 - loss: 1.0921 - val_accuracy: 0.4682 - val_loss: 1.0350\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4561 - loss: 1.0386 - val_accuracy: 0.5838 - val_loss: 0.8901\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6368 - loss: 0.7909 - val_accuracy: 0.8728 - val_loss: 0.6364\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7492 - loss: 0.6251 - val_accuracy: 0.8844 - val_loss: 0.3823\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7872 - loss: 0.5164 - val_accuracy: 0.9133 - val_loss: 0.3356\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8188 - loss: 0.4378 - val_accuracy: 0.9017 - val_loss: 0.2889\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8421 - loss: 0.4043 - val_accuracy: 0.8844 - val_loss: 0.3298\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8493 - loss: 0.3625 - val_accuracy: 0.9133 - val_loss: 0.2763\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8465 - loss: 0.3764 - val_accuracy: 0.9249 - val_loss: 0.2222\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8740 - loss: 0.3168 - val_accuracy: 0.9133 - val_loss: 0.2051\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8775 - loss: 0.3117 - val_accuracy: 0.9711 - val_loss: 0.1338\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8902 - loss: 0.3042 - val_accuracy: 0.9711 - val_loss: 0.1428\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9005 - loss: 0.2628 - val_accuracy: 0.9133 - val_loss: 0.2068\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9004 - loss: 0.2763 - val_accuracy: 0.9711 - val_loss: 0.1041\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9105 - loss: 0.2317 - val_accuracy: 0.9711 - val_loss: 0.0796\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9206 - loss: 0.2249 - val_accuracy: 0.9653 - val_loss: 0.0833\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9121 - loss: 0.2174 - val_accuracy: 0.9769 - val_loss: 0.0752\n",
            "Epoch 25/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9275 - loss: 0.2070 - val_accuracy: 0.9769 - val_loss: 0.0605\n",
            "Epoch 26/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9360 - loss: 0.1846 - val_accuracy: 0.9711 - val_loss: 0.0780\n",
            "Epoch 27/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9286 - loss: 0.2135 - val_accuracy: 0.9769 - val_loss: 0.0595\n",
            "Epoch 28/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9491 - loss: 0.1732 - val_accuracy: 0.9769 - val_loss: 0.0585\n",
            "Epoch 29/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9351 - loss: 0.1853 - val_accuracy: 0.9884 - val_loss: 0.0740\n",
            "Epoch 30/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9427 - loss: 0.1759 - val_accuracy: 0.9769 - val_loss: 0.0583\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n",
            "Confusion Matrix:\n",
            "[[58  0  0]\n",
            " [ 0 55  2]\n",
            " [ 0  2 56]]\n",
            "Precision: 0.9768, Recall: 0.9768, Accuracy: 0.9769, F1 Score: 0.9768\n",
            "\n",
            "=== 5-Fold Validation Summary ===\n",
            "Avg Precision: 0.9617\n",
            "Avg Recall:    0.9608\n",
            "Avg Accuracy:  0.9607\n",
            "Avg F1 Score:  0.9608\n",
            "Best Fold: 1 with F1 Score: 0.9827\n",
            "Best model saved at: best_cnn_lstm_model.keras\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.3430 - loss: 1.0996 - val_accuracy: 0.3741 - val_loss: 1.0902\n",
            "Epoch 2/30\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.3615 - loss: 1.0900 - val_accuracy: 0.5427 - val_loss: 0.9641\n",
            "Epoch 3/30\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6251 - loss: 0.8091 - val_accuracy: 0.8129 - val_loss: 0.4200\n",
            "Epoch 4/30\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8529 - loss: 0.3781 - val_accuracy: 0.9215 - val_loss: 0.2477\n",
            "Epoch 5/30\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9110 - loss: 0.2559 - val_accuracy: 0.9376 - val_loss: 0.1704\n",
            "Epoch 6/30\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9307 - loss: 0.1926 - val_accuracy: 0.9376 - val_loss: 0.1724\n",
            "Epoch 7/30\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9382 - loss: 0.1722 - val_accuracy: 0.9330 - val_loss: 0.1641\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\n",
            "=== Final Test Fold (Fold 6) Evaluation ===\n",
            "[[58  0  0]\n",
            " [ 0 57  0]\n",
            " [ 0  1 57]]\n",
            "Test Accuracy:  0.9942\n",
            "Test Precision: 0.9943\n",
            "Test Recall:    0.9943\n",
            "Test F1 Score:  0.9942\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, MaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(492)\n",
        "\n",
        "# Load data\n",
        "def import_data():\n",
        "    data = pd.read_csv('mergedshuffledPlankV2keypoints.csv')\n",
        "    x = data.iloc[:, :-1].values\n",
        "    y = data['correct'].astype(int).values\n",
        "    y = np.searchsorted(np.unique(y), y)\n",
        "    scaler = MinMaxScaler()\n",
        "    x = scaler.fit_transform(x)\n",
        "    return x, y\n",
        "\n",
        "# Balance dataset using SMOTE\n",
        "def balance_data(x, y):\n",
        "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "    x_resampled, y_resampled = smote.fit_resample(x, y)\n",
        "    print(\"Balanced class distribution:\")\n",
        "    print(pd.Series(y_resampled).value_counts())\n",
        "    return x_resampled, y_resampled\n",
        "\n",
        "# Add Gaussian noise\n",
        "def augment_data(x, noise_factor=0.05):\n",
        "    noise = np.random.normal(loc=0.0, scale=noise_factor, size=x.shape)\n",
        "    return x + noise\n",
        "\n",
        "# Model definition\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main\n",
        "x, y = import_data()\n",
        "x, y = balance_data(x, y)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Create 6 stratified folds\n",
        "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(x, y))\n",
        "train_val_folds = folds[:5]\n",
        "test_fold = folds[5]\n",
        "\n",
        "# Initialise trackers\n",
        "best_model_path = \"best_cnn_lstm_model.keras\"\n",
        "best_fold, best_f1 = None, -1\n",
        "precision_list, recall_list, accuracy_list, f1_list = [], [], [], []\n",
        "\n",
        "# Perform 5-Fold CV on first 5 folds\n",
        "for fold_index, (train_index, val_index) in enumerate(train_val_folds, start=1):\n",
        "    x_train, x_val = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Augment training data\n",
        "    x_train = augment_data(x_train, noise_factor=0.05)\n",
        "\n",
        "    # Reshape\n",
        "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    # Class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_index} ===\")\n",
        "    print(\"Class distribution:\", pd.Series(y_val).value_counts().to_dict())\n",
        "\n",
        "    # Model & Callbacks\n",
        "    model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        validation_data=(x_val, y_val),\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    preds = np.argmax(model.predict(x_val), axis=1)\n",
        "    precision = precision_score(y_val, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, preds, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, preds))\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Save metrics\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    accuracy_list.append(accuracy)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_fold = fold_index\n",
        "        model.save(best_model_path)\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n=== 5-Fold Validation Summary ===\")\n",
        "print(f\"Avg Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Avg Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Avg Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Avg F1 Score:  {np.mean(f1_list):.4f}\")\n",
        "print(f\"Best Fold: {best_fold} with F1 Score: {best_f1:.4f}\")\n",
        "print(f\"Best model saved at: {best_model_path}\")\n",
        "\n",
        "# === Final Test Fold Evaluation ===\n",
        "test_index = test_fold[1]\n",
        "train_index = np.concatenate([f[0] for f in train_val_folds])\n",
        "x_train, x_test = x[train_index], x[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Augment and reshape\n",
        "x_train = augment_data(x_train, noise_factor=0.05)\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Final model training on Fold 6\n",
        "final_model = create_cnn_lstm_model(input_shape=(x_train.shape[1], x_train.shape[2]), num_classes=num_classes)\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=2, min_delta=0.001, restore_best_weights=True)\n",
        "\n",
        "final_model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on final test set\n",
        "test_preds = np.argmax(final_model.predict(x_test), axis=1)\n",
        "test_accuracy = accuracy_score(y_test, test_preds)\n",
        "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
        "test_precision = precision_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "test_recall = recall_score(y_test, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n=== Final Test Fold (Fold 6) Evaluation ===\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}